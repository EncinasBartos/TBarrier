{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T13:39:31.134199Z",
     "start_time": "2022-02-09T13:39:31.126195Z"
    }
   },
   "source": [
    "# Turbulent channel flow data\n",
    "\n",
    "We will use the turbulent channel flow data from the [Johns Hopkins Turbulence Database(JHTDB)](http://turbulence.pha.jhu.edu/Channel_Flow.aspx) Re=1000 Channel flow. The JHTDB channel flow data is available on a 2048 × 512 × 1536 grid for a domain of\n",
    "size $ 8 \\pi h \\times 2h \\times 3\\pi h $, where h is the half-channel height. The DNS timestep ∆t = 0.0013\n",
    "non-dimensional units, with the stored simulation timestep, δt = 5∆t, or approximately\n",
    "one channel flow-through time. The analysis herein is conducted over 100 frames spanning\n",
    "the entire simulation database with a duration of 4,000 channel flow-through times from\n",
    "t = 0 to t = 5.9935. All figures and analysis will be displayed in non-dimensional half-channel\n",
    "height units (h = 1).\n",
    "\n",
    "More information about the flow-field can be found in [Channel](README_CHANNEL.pdf). Due to computational and memory space reasons, we download the data over a reduced section of the available domain. In order to download the turbulence dataset, a \"token\" must be requested from JHTDB. The parameters of the turbulence channel flow simulation are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T15:57:31.717973Z",
     "start_time": "2022-06-13T15:57:31.702049Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"Channel.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T15:57:31.725338Z",
     "start_time": "2022-06-13T15:57:31.721168Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# import sys/os\n",
    "import sys, os\n",
    "\n",
    "# get current directory\n",
    "path = os.getcwd()\n",
    "\n",
    "# get parent directory\n",
    "parent_directory = os.path.sep.join(path.split(os.path.sep)[:-2])\n",
    "\n",
    "# add utils folder to current working path\n",
    "sys.path.append(parent_directory+\"/subfunctions/utils\")\n",
    "\n",
    "# add integration folder to current working path\n",
    "sys.path.append(parent_directory+\"/subfunctions/integration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T15:57:32.178729Z",
     "start_time": "2022-06-13T15:57:31.728941Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import h5py\n",
    "import h5py\n",
    "\n",
    "# import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Import velocity data from file in data-folder\n",
    "f = h5py.File('channel.h5', 'r')\n",
    "\n",
    "U, V, W = [], [], []\n",
    "\n",
    "for key in f.keys():\n",
    "    if key[:8] == \"Velocity\":\n",
    "        U.append(f[key][:,:,:,0])\n",
    "        V.append(f[key][:,:,:,1])\n",
    "        W.append(f[key][:,:,:,2])\n",
    "\n",
    "U = np.array(U).transpose(2,3,1,0) # array (NY, NX, NZ, NT)\n",
    "V = np.array(V).transpose(2,3,1,0) # array (NY, NX, NZ, NT)\n",
    "W = np.array(W).transpose(2,3,1,0) # array (NY, NX, NZ, NT)\n",
    "x = f['xcoor'][:].reshape(1,-1) # array (1, NX)\n",
    "y = f['ycoor'][:].reshape(1,-1) # array (1, NY)\n",
    "z = f['zcoor'][:].reshape(1,-1) # array (1, NZ)\n",
    "time_data = np.linspace(0, 25.9935, U.shape[-1], endpoint = True).reshape(1,-1) # array (1, NT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T15:57:32.181893Z",
     "start_time": "2022-06-13T15:57:31.704Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# Number of cores for parallel computing\n",
    "Ncores = 16 # int\n",
    "\n",
    "t0 = 0 # float 0 <= t0 < 25.9935\n",
    "\n",
    "# Periodic boundary conditions\n",
    "periodic_x = True # bool\n",
    "periodic_y = False # bool\n",
    "periodic_z = True # bool\n",
    "periodic = [periodic_x, periodic_y, periodic_z]\n",
    "\n",
    "# Unsteady velocity field\n",
    "bool_unsteady = False # bool\n",
    "\n",
    "# Defined domain\n",
    "defined_domain = np.isfinite(U).astype(int) # array (NY, NX, NZ)\n",
    "\n",
    "## Compute meshgrid of dataset\n",
    "X, Y, Z = np.meshgrid(x, y, z) # array (NY, NX), array (NY, NX, NZ)\n",
    "\n",
    "## Resolution of meshgrid\n",
    "dx_data = X[0,1,0]-X[0,0,0] # float\n",
    "dy_data = Y[1,0,0]-Y[0,0,0] # float\n",
    "dz_data = Y[0,0,1]-Z[0,0,0] # float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T15:57:32.183986Z",
     "start_time": "2022-06-13T15:57:31.705Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Import function to compute laplacian of velocity from structured velocity data.\n",
    "from ipynb.fs.defs.laplacian_velocity import laplacian_velocity\n",
    "\n",
    "Lap_u, Lap_v, Lap_w  = laplacian_velocity(t0, X, Y, Z, U, V, W, periodic, bool_unsteady, 0, time_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T15:57:32.186267Z",
     "start_time": "2022-06-13T15:57:31.706Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.io import savemat\n",
    "\n",
    "mat_data = {\"Lap_u\": Lap_u, \"Lap_v\": Lap_v, \"Lap_w\": Lap_w, \"xspan\": X[0,:,0], \"yspan\": Y[:,0,0], \"zspan\": Z[0,0,:]}\n",
    "\n",
    "savemat(\"Channel.mat\", mat_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: The mat-file \"MomentumBarrierField.mat\", stored in the same directory is originally found on the github account [haller-group](https://github.com/haller-group/TRA_TSE). It focuses on a reduced region of the JHTDB and has been included in order to reproduce the results from [1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[1] Aksamit, N.O., Haller, G. (2021). Objective Momentum Barriers in Wall Turbulence. In Review"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
