{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T13:31:20.561180Z",
     "start_time": "2021-10-01T13:31:20.421091Z"
    }
   },
   "outputs": [],
   "source": [
    "# LCS\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "class LCS:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T13:31:20.576169Z",
     "start_time": "2021-10-01T13:31:20.562180Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _FTLE_(self):\n",
    "        \n",
    "        if hasattr(self, 'C') == False:\n",
    "        \n",
    "            self._cauchy_green_strain()\n",
    "            \n",
    "        print(\"=================FTLE=================\")\n",
    "    \n",
    "        self.FTLE = np.zeros((self.len_Y, self.len_X, self.dim))*np.nan\n",
    "        \n",
    "        for i in range(self.len_Y):\n",
    "        \n",
    "            for j in range(self.len_X):\n",
    "                \n",
    "                lambda_min, lambda_max, v_min, v_max = self._eigenvalues_and_eigenvectors(self.C[i, j, :, :])\n",
    "                        \n",
    "                if lambda_min > 0:\n",
    "                    \n",
    "                    self.FTLE[i, j, 0] = 1/(2*(self.lenT))*np.log(lambda_min)\n",
    "                    self.FTLE[i, j, 1] = 1/(2*(self.lenT))*np.log(lambda_max)\n",
    "                        \n",
    "        return self.FTLE[:,:,0], self.FTLE[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T13:31:20.591523Z",
     "start_time": "2021-10-01T13:31:20.577140Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _PRA_(self):\n",
    "            \n",
    "        if hasattr(self, 'grad_Fmap_grid') == False:\n",
    "        \n",
    "            self._grad_Fmap_grid()\n",
    "            \n",
    "        print(\"=================PRA=================\")\n",
    "            \n",
    "        self.PRA = np.zeros(self.X_domain.shape)\n",
    "            \n",
    "        for i in range(self.len_Y):\n",
    "        \n",
    "            for j in range(self.len_X):\n",
    "                \n",
    "                U, S, V = self._svd(self.grad_Fmap_grid[i, j, :, :])\n",
    "                \n",
    "                self.PRA[i, j] = np.arccos(U[0, 0]*V[0, 0]+U[0, 1]*V[0, 1])\n",
    "        \n",
    "        return self.PRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T13:31:20.623438Z",
     "start_time": "2021-10-01T13:31:20.592521Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _LAVD_(self):\n",
    "        \n",
    "        if hasattr(self, 'trajectory_grid') == False:\n",
    "            \n",
    "            self._trajectory_grid()\n",
    "            \n",
    "        print(\"=================LAVD=================\")\n",
    "            \n",
    "        def parallelization(k, t):\n",
    "                \n",
    "            self.omega = self._vorticity(t)\n",
    "                \n",
    "            spatially_averaged_vorticity = np.nanmean(self.omega.ravel())\n",
    "                \n",
    "            LVD = np.zeros((self.len_Y, self.len_X))\n",
    "            \n",
    "            for i in range(self.len_Y):\n",
    "            \n",
    "                for j in range(self.len_X):\n",
    "                    \n",
    "                    x = np.array([self.trajectory_grid[i, j, 0, k], self.trajectory_grid[i, j, 1, k]]).reshape(1, -1)\n",
    "\n",
    "                    W = self._vorticity_tensor(x, t)\n",
    "                    \n",
    "                    omega = W[0, 1]-W[1, 0]\n",
    "                \n",
    "                    LVD[i, j] = np.abs(omega-spatially_averaged_vorticity)\n",
    "                    \n",
    "            return LVD\n",
    "        \n",
    "        self.LVD = np.array(Parallel(n_jobs=self.Ncores, verbose = 1)(delayed(parallelization)(k, t) for k, t in tqdm(enumerate(self.time), total=len(self.time))))\n",
    "        \n",
    "        self.LAVD = np.nanmean(self.LVD, axis = 0)\n",
    "        \n",
    "        return self.LAVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T13:31:20.639395Z",
     "start_time": "2021-10-01T13:31:20.624436Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _TRA_(self):\n",
    "        \n",
    "        if hasattr(self, 'trajectory_grid') == False:\n",
    "            \n",
    "            self._trajectory_grid()\n",
    "\n",
    "        print(\"=================TRA=================\")\n",
    "        \n",
    "        self.TRA = np.zeros((self.len_Y, self.len_X))\n",
    "            \n",
    "        for i in range(self.len_Y):\n",
    "            \n",
    "            for j in range(self.len_X):\n",
    "                    \n",
    "                velx0 = self.velocity_grid[i, j, 0, 0]\n",
    "                vely0 = self.velocity_grid[i, j, 1, 0]\n",
    "                    \n",
    "                vel0 = np.sqrt(velx0**2+vely0**2)\n",
    "                    \n",
    "                velxN = self.velocity_grid[i, j, 0, -1]\n",
    "                velyN = self.velocity_grid[i, j, 1, -1]\n",
    "                \n",
    "                vel1 = np.sqrt(velxN**2+velyN**2)\n",
    "                \n",
    "                self.TRA[i, j] = np.abs(np.arccos((velx0*velxN+vely0*velyN)/(vel0*vel1)))\n",
    "        \n",
    "        return self.TRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T13:31:20.655353Z",
     "start_time": "2021-10-01T13:31:20.640393Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _TRA_bar_(self):\n",
    "        \n",
    "        if hasattr(self, 'trajectory_grid') == False:\n",
    "            \n",
    "            self._trajectory_grid()\n",
    "\n",
    "        print(\"=================TRA_bar=================\")\n",
    "        \n",
    "        self.TR_bar = np.zeros((self.len_Y, self.len_X, self.lenT-2))\n",
    "        \n",
    "        for k in tqdm(range(self.lenT-2), total = self.lenT-2):\n",
    "            \n",
    "            for i in range(self.len_Y):\n",
    "            \n",
    "                for j in range(self.len_X):\n",
    "                    \n",
    "                    velx0 = self.velocity_grid[i, j, 0, k]\n",
    "                    vely0 = self.velocity_grid[i, j, 1, k]\n",
    "                    \n",
    "                    vel0 = np.sqrt(velx0**2+vely0**2)\n",
    "                    \n",
    "                    velx1 = self.velocity_grid[i, j, 0, k + 1]\n",
    "                    vely1 = self.velocity_grid[i, j, 1, k + 1]\n",
    "                \n",
    "                    vel1 = np.sqrt(velx1**2+vely1**2)\n",
    "                \n",
    "                    self.TR_bar[i, j, k-1] = np.abs(np.arccos((velx0*velx1+vely0*vely1)/(vel0*vel1)))\n",
    "        \n",
    "        self.TRA_bar = np.nanmean(self.TR_bar, axis = 2)/(self.tN-self.t0)\n",
    "        \n",
    "        return self.TRA_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T13:31:20.670313Z",
     "start_time": "2021-10-01T13:31:20.656350Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _TSE_(self):\n",
    "    \n",
    "        if hasattr(self, 'trajectory_grid') == False:\n",
    "            \n",
    "            self._trajectory_grid()\n",
    "\n",
    "        print(\"=================TSE=================\")\n",
    "        \n",
    "        self.TSE = np.zeros((self.len_Y, self.len_X))\n",
    "            \n",
    "        for i in range(self.len_Y):\n",
    "            \n",
    "            for j in range(self.len_X):\n",
    "                    \n",
    "                velx0 = self.velocity_grid[i, j, 0, 0]\n",
    "                vely0 = self.velocity_grid[i, j, 1, 0]\n",
    "                    \n",
    "                vel0 = np.sqrt(velx0**2+vely0**2)\n",
    "                    \n",
    "                velxN = self.velocity_grid[i, j, 0, -1]\n",
    "                velyN = self.velocity_grid[i, j, 1, -1]\n",
    "                \n",
    "                velN = np.sqrt(velxN**2+velyN**2)\n",
    "                \n",
    "                self.TSE[i, j] = 1/(self.tN-self.t0)*np.log(velN/vel0)\n",
    "        \n",
    "        return self.TSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T13:31:20.685273Z",
     "start_time": "2021-10-01T13:31:20.671310Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _TSE_bar_(self):\n",
    "        \n",
    "        if hasattr(self, 'trajectory_grid') == False:\n",
    "            \n",
    "            self._trajectory_grid()\n",
    "\n",
    "        print(\"=================TSE_bar=================\")\n",
    "        \n",
    "        self.TSE_bar = np.zeros((self.len_Y, self.len_X, self.lenT-2))\n",
    "        \n",
    "        for k in tqdm(range(self.lenT-2), total = self.lenT-2):\n",
    "            \n",
    "            for i in range(self.len_Y):\n",
    "            \n",
    "                for j in range(self.len_X):\n",
    "                    \n",
    "                    velx0 = self.velocity_grid[i, j, 0, k]\n",
    "                    vely0 = self.velocity_grid[i, j, 1, k]\n",
    "                    \n",
    "                    vel0 = np.sqrt(velx0**2+vely0**2)\n",
    "                    \n",
    "                    velx1 = self.velocity_grid[i, j, 0, k + 1]\n",
    "                    vely1 = self.velocity_grid[i, j, 1, k + 1]\n",
    "                \n",
    "                    vel1 = np.sqrt(velx1**2+vely1**2)\n",
    "                \n",
    "                    self.TSE_bar[i, j, k] = np.abs(np.log(vel1/vel0))\n",
    "        \n",
    "        self.TSE_bar = np.nanmean(self.TSE_bar, axis = 2)/(self.tN-self.t0)\n",
    "        \n",
    "        return self.TRA_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T13:31:20.716190Z",
     "start_time": "2021-10-01T13:31:20.687269Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _hyperbolic_LCS_local_variational_theory(self, max_distance = 1, type = \"shrinklines\", max_line_length = 10, step_size = None):\n",
    "        \n",
    "        if step_size is None:\n",
    "            step_size = self.dx/20\n",
    "        \n",
    "        self.lambda_max = np.zeros((self.len_Y, self.len_X))\n",
    "        self.eigenvector_max = np.zeros((self.len_Y, self.len_X, self.dim))\n",
    "        self.lambda_min = np.zeros((self.len_Y, self.len_X))\n",
    "        self.eigenvector_min = np.zeros((self.len_Y, self.len_X, self.dim))\n",
    "        \n",
    "        for i in range(self.len_Y):\n",
    "        \n",
    "            for j in range(self.len_X):\n",
    "        \n",
    "                lambda_min, lambda_max, v_min, v_max = self._eigenvalues_and_eigenvectors(self.C[i, j, :, :])\n",
    "        \n",
    "                if np.isfinite(lambda_max) and np.isfinite(lambda_min):\n",
    "                \n",
    "                    self.lambda_max[i, j] = lambda_max\n",
    "                    self.lambda_min[i, j] = lambda_min\n",
    "                    self.eigenvector_max[i, j, :] = v_max\n",
    "                    self.eigenvector_min[i, j, :] = v_min\n",
    "\n",
    "        if type == \"shrinklines\":\n",
    "    \n",
    "            self.eigen = self.eigenvector_min\n",
    "        \n",
    "            # Find local maxima of the max eigenvalue field\n",
    "            peak_x, peak_y, peak_field = self._find_2D_peaks(max_distance, self.X_domain, self.Y_domain, self.lambda_max)\n",
    "            \n",
    "        elif type == \"stretchlines\":\n",
    "    \n",
    "            self.eigen = self.eigenvector_max\n",
    "        \n",
    "            # Find local minima of the max eigenvalue field\n",
    "            peak_x, peak_y, peak_field = self._find_2D_peaks(max_distance, self.X_domain, self.Y_domain, -self.lambda_max)\n",
    "        \n",
    "        else:    \n",
    "            print(\"Variable type should either be strainlines or stretchlines\")\n",
    "        \n",
    "        self.Interp_lambda_min = self._gridded_Interpolation(self.Y_domain, self.X_domain, self.lambda_min, \"cubic\")\n",
    "        self.Interp_lambda_max = self._gridded_Interpolation(self.Y_domain, self.X_domain, self.lambda_max, \"cubic\")\n",
    "        self.Interp_eigen_x = self._gridded_Interpolation(self.Y_domain, self.X_domain, self.eigen[:,:,0], \"cubic\")\n",
    "        self.Interp_eigen_y = self._gridded_Interpolation(self.Y_domain, self.X_domain, self.eigen[:,:,1], \"cubic\")\n",
    "    \n",
    "        x_strainlines = []\n",
    "        y_strainlines = []\n",
    "        \n",
    "        for i in tqdm(range(len(peak_x))):\n",
    "            \n",
    "            x = np.array([peak_x[i], peak_y[i]])\n",
    "            bool_loc_max = True\n",
    "            \n",
    "            for j in range(len(x_strainlines)):\n",
    "                    \n",
    "                if np.sqrt((x[0]-x_strainlines[j])**2+(x[1]-y_strainlines[j])**2) < max_distance:\n",
    "                    bool_loc_max = False\n",
    "                    break\n",
    "            \n",
    "            x_forward_update = x\n",
    "            x_backward_update = x\n",
    "        \n",
    "            dist_forward = 0\n",
    "            dist_backward = 0\n",
    "            dist_total = 0\n",
    "        \n",
    "            counter = 0\n",
    "        \n",
    "            while dist_total <= max_line_length and bool_loc_max == True:\n",
    "                \n",
    "                if counter == 0:\n",
    "                    \n",
    "                    vx = self.Interp_eigen_x(x[1], x[0])[0][0]\n",
    "                    vy = self.Interp_eigen_y(x[1], x[0])[0][0]\n",
    "                    \n",
    "                    x_prime_forward = np.array([vx, vy])\n",
    "                    x_prime_backward = -np.array([vx, vy])\n",
    "                    \n",
    "                if x_forward_update is not None:\n",
    "                    \n",
    "                    x_forward = x_forward_update\n",
    "                    x_strainlines.append(x_forward[0])\n",
    "                    y_strainlines.append(x_forward[1])\n",
    "                    x_forward_update, x_prime_forward = self._RK4_tensorlines_orientational_discontinuity(x_forward, x_prime_forward, step_size)\n",
    "                    \n",
    "                    if x_forward_update is not None:\n",
    "                        dist_forward = np.sqrt((x_forward_update[0]-x_forward[0])**2+(x_forward_update[1]-x_forward[1])**2)\n",
    "                \n",
    "                if x_backward_update is not None:\n",
    "                    \n",
    "                    x_backward = x_backward_update\n",
    "                    x_strainlines.append(x_backward[0])\n",
    "                    y_strainlines.append(x_backward[1])\n",
    "                    x_backward_update, x_prime_backward = self._RK4_tensorlines_orientational_discontinuity(x_backward, x_prime_backward, step_size)\n",
    "                    if x_backward_update is not None:\n",
    "                        dist_backward = np.sqrt((x_backward_update[0]-x_backward[0])**2+(x_backward_update[1]-x_backward[1])**2)\n",
    "        \n",
    "                dist_total += dist_forward+dist_backward\n",
    "                dist_forward = 0\n",
    "                dist_backward = 0\n",
    "            \n",
    "                if x_forward_update is None and x_backward_update is None:\n",
    "                    bool_loc_max = False\n",
    "                \n",
    "                counter += 1\n",
    "    \n",
    "        return x_strainlines, y_strainlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T13:31:20.731150Z",
     "start_time": "2021-10-01T13:31:20.717187Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _elliptic_LCS_local_variational_theory(self):\n",
    "        \n",
    "        print(\"=================Elliptic LCS from local variational theory=================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T13:31:20.746110Z",
     "start_time": "2021-10-01T13:31:20.732147Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _hyperbolic_LCS_global_variational_theory(self):\n",
    "        \n",
    "        print(\"=================Hyperbolic LCS from global variational theory=================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T13:31:20.761070Z",
     "start_time": "2021-10-01T13:31:20.747107Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _elliptic_LCS_global_variational_theory(self):\n",
    "        \n",
    "        print(\"=================Elliptic LCS from global variational theory=================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T13:31:20.777027Z",
     "start_time": "2021-10-01T13:31:20.762067Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _vorticity(self, t):\n",
    "        \n",
    "        self.omega = np.zeros((self.len_Y, self.len_X))\n",
    "        \n",
    "        for i in range(self.len_Y):\n",
    "            \n",
    "            for j in range(self.len_X):\n",
    "                \n",
    "                x = np.array([self.X_domain[i, j], self.Y_domain[i, j]]).reshape(1, -1)\n",
    "    \n",
    "                W = self._vorticity_tensor(x, t)\n",
    "                \n",
    "                self.omega[i, j] = W[0, 1]-W[1, 0]\n",
    "                \n",
    "        return self.omega              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T13:31:20.791987Z",
     "start_time": "2021-10-01T13:31:20.778025Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _find_ridges(self, Field, threshold = None, type = \"ridge\", method = \"threshold\", resolution = 1, ds = 1, n_iterations = 100):\n",
    "        \n",
    "        if type == \"ridge\":\n",
    "            \n",
    "            sign = 1\n",
    "            \n",
    "            if threshold is None:\n",
    "            \n",
    "                print(\"Threshold value is None --> Specify threshold.\")\n",
    "                print(\"If not specified, threshold is set to \", 0.1, \" of the maximum value of the given scalar field\")\n",
    "            \n",
    "                threshold = .1*np.nanmax(Field)\n",
    "            \n",
    "        elif type == \"trench\":\n",
    "            \n",
    "            sign = -1\n",
    "                  \n",
    "            if threshold is None:\n",
    "            \n",
    "                print(\"Threshold value is None --> Specify threshold.\")\n",
    "                print(\"If not specified, threshold is set to \", 0.1, \" of the maximum value of the given scalar field\")\n",
    "            \n",
    "                threshold = .1*np.nanmin(Field)\n",
    "            \n",
    "        if method == \"threshold\":\n",
    "            \n",
    "            mask = (Field >= threshold)\n",
    "            \n",
    "            extrema_x = self.X_domain[mask].ravel()\n",
    "            extrema_y = self.Y_domain[mask].ravel()\n",
    "            \n",
    "            return extrema_x, extrema_y\n",
    "            \n",
    "        elif method == \"gradient\":\n",
    "            \n",
    "            Field[np.isnan(Field)] = 0\n",
    "            \n",
    "            Interpolant_Field = self._Interpolation(self.Y_domain, self.X_domain, Field, method = \"cubic\")\n",
    "            \n",
    "            grad_Field = np.zeros((Field.shape[0], Field.shape[1], 2))\n",
    "            \n",
    "            for i in range(1, Field.shape[0]-1):\n",
    "                \n",
    "                for j in range(1, Field.shape[1]-1):\n",
    "                    \n",
    "                    dy = (self.Y_domain[i+1,0] - self.Y_domain[i-1, 0])/2\n",
    "                    dx = (self.X_domain[0, j+1] - self.X_domain[0, j-1])/2\n",
    "\n",
    "                    grad_Field[i, j, 0] = (Interpolant_Field(self.Y_domain[i, j], self.X_domain[i, j]+.1*dx)[0][0]-Interpolant_Field(self.Y_domain[i, j], self.X_domain[i, j]-.1*dx)[0][0])/(2*.1*dx)\n",
    "                    grad_Field[i, j, 1] = (Interpolant_Field(self.Y_domain[i, j]+.1*dy, self.X_domain[i, j])[0][0]-Interpolant_Field(self.Y_domain[i, j]-.1*dy, self.X_domain[i, j])[0][0])/(2*.1*dy)\n",
    "        \n",
    "            grad_Fieldx = grad_Field[:, :, 0]\n",
    "            grad_Fieldy = grad_Field[:, :, 1]\n",
    "            grad_Fieldx[np.isnan(grad_Fieldx)] = 0\n",
    "            grad_Fieldy[np.isnan(grad_Fieldy)] = 0\n",
    "            \n",
    "            Interpolant_gradx_Field = self._Interpolation(self.Y_domain, self.X_domain, grad_Fieldx)\n",
    "            Interpolant_grady_Field = self._Interpolation(self.Y_domain, self.X_domain, grad_Fieldy)\n",
    "            \n",
    "            x_grid = np.linspace(np.min(self.X_domain), np.max(self.X_domain), self.Y_domain.shape[0]*resolution)\n",
    "            y_grid = np.linspace(np.min(self.Y_domain), np.max(self.Y_domain), self.Y_domain.shape[1]*resolution)\n",
    "            \n",
    "            extrema_x = []\n",
    "            extrema_y = []\n",
    "            \n",
    "            for x in tqdm(x_grid, total = len(x_grid)):\n",
    "                    \n",
    "                for y in y_grid:\n",
    "                    \n",
    "                    x_eval = x\n",
    "                    y_eval = y\n",
    "    \n",
    "                    loc = self._check_location(np.array([x_eval, y_eval]).reshape(1, -1))[0]\n",
    "                        \n",
    "                    gradient = 10\n",
    "                    \n",
    "                    iter = 0\n",
    "                        \n",
    "                    while iter < n_iterations and loc == \"IN\" and Interpolant_Field(y_eval, x_eval)[0][0] > threshold:\n",
    "                            \n",
    "                        loc = self._check_location(np.array([x_eval, y_eval]).reshape(1, -1))[0]\n",
    "                        \n",
    "                        gradx = Interpolant_gradx_Field(y_eval, x_eval)[0][0]\n",
    "                        grady = Interpolant_grady_Field(y_eval, x_eval)[0][0]\n",
    "                        \n",
    "                        gradient = np.sqrt(gradx**2+grady**2)\n",
    "                        \n",
    "                        x_eval = x_eval + sign * ds * gradx/gradient*dx\n",
    "                        y_eval = y_eval + sign * ds * grady/gradient*dy\n",
    "                        \n",
    "                        iter += 1\n",
    "                    \n",
    "                        extrema_x.append(x_eval)\n",
    "                        extrema_y.append(y_eval)\n",
    "            \n",
    "            return extrema_x, extrema_y\n",
    "\n",
    "        else:\n",
    "            \n",
    "            print(\"The method argument is not valid. Use either threshold or gradient\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T13:31:20.806947Z",
     "start_time": "2021-10-01T13:31:20.792985Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _find_2D_peaks(self, max_distance, X, Y, Field):\n",
    "        \n",
    "        def _find_all_local_maxima(X, Y, Field):\n",
    "            \n",
    "            loc_max_x, loc_max_y, loc_max_field = [], [], []\n",
    "            \n",
    "            for i in range(2, X.shape[0]-2):\n",
    "                \n",
    "                for j in range(2, Y.shape[1]-2):\n",
    "                    \n",
    "                    if np.isfinite(Field[i, j]) and Field[i, j] > Field[i+1, j] and Field[i, j] > Field[i-1, j] and Field[i, j] > Field[i, j+1] and Field[i, j] > Field[i, j-1]:\n",
    "                        \n",
    "                        loc_max_x.append(X[i, j])\n",
    "                        loc_max_y.append(Y[i, j])\n",
    "                        loc_max_field.append(Field[i, j])\n",
    "            \n",
    "            return loc_max_x, loc_max_y, loc_max_field\n",
    "        \n",
    "        loc_max_x, loc_max_y, loc_max_field = _find_all_local_maxima(X, Y, Field)\n",
    "        \n",
    "        n_loc_max = len(loc_max_x)\n",
    "        \n",
    "        peak_x, peak_y, peak_field = [], [], []\n",
    "        \n",
    "        for i in range(n_loc_max):\n",
    "            \n",
    "            bool_loc_max = True\n",
    "    \n",
    "            for j in range(n_loc_max):\n",
    "            \n",
    "                if i != j and loc_max_field[i] < loc_max_field[j] and np.sqrt((loc_max_x[i]-loc_max_x[j])**2+(loc_max_y[i]-loc_max_y[j])**2) <= max_distance:\n",
    "                    \n",
    "                    bool_loc_max = False\n",
    "                \n",
    "            if bool_loc_max:\n",
    "                \n",
    "                peak_x.append(loc_max_x[i])\n",
    "                peak_y.append(loc_max_y[i])\n",
    "                peak_field.append(loc_max_field[i])\n",
    "                \n",
    "        return peak_x, peak_y, peak_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T13:31:20.822905Z",
     "start_time": "2021-10-01T13:31:20.807945Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _differential_system_tensorlines_orientational_discontinuity(self, x, x_prime):\n",
    "                \n",
    "        # Check for orientational discontinuity by introducing appropriate scaling\n",
    "                \n",
    "        vx = self.Interp_eigen_x(x[1], x[0])[0][0]\n",
    "        vy = self.Interp_eigen_y(x[1], x[0])[0][0]\n",
    "            \n",
    "        lambda_max = self.Interp_lambda_max(x[1], x[0])[0][0]\n",
    "        lambda_min = self.Interp_lambda_min(x[1], x[0])[0][0]\n",
    "            \n",
    "        alpha = ((lambda_max-lambda_min)/(lambda_max+lambda_min))**2\n",
    "            \n",
    "        scaling = np.sign(vx*x_prime[0]+vy*x_prime[1])*alpha\n",
    "            \n",
    "        return scaling*np.array([vx, vy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T00:26:37.593018Z",
     "start_time": "2021-10-02T00:26:37.574068Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _RK4_tensorlines_orientational_discontinuity(self, x, x_prime, ds):\n",
    "        \n",
    "        # Define starting point.\n",
    "        x1 = x\n",
    "        \n",
    "        # If x is outside defined domain --> vel is None --> _RK4 returns \"None\" and integration will stop.\n",
    "            \n",
    "        # Compute x_prime at the beginning of the time-step\n",
    "        \n",
    "        loc = self._check_location(x1)[0]\n",
    "        \n",
    "        if loc != \"IN\" or self.Interp_lambda_max(x1[1], x1[0])[0][0] < 1:\n",
    "            return None, None\n",
    "        x_prime = self._differential_system_tensorlines_orientational_discontinuity(x1, x_prime)  \n",
    "        k1 = ds * x_prime\n",
    "\n",
    "        #  position and time at the first midpoint.\n",
    "        x2 = x1 + .5 * k1\n",
    "        loc = self._check_location(x2)[0]\n",
    "        \n",
    "        if loc != \"IN\" or self.Interp_lambda_max(x2[1], x2[0])[0][0] < 1:\n",
    "            return None, None\n",
    "        \n",
    "        # Compute x_prime at the first midpoint.\n",
    "        x_prime = self._differential_system_tensorlines_orientational_discontinuity(x2, x_prime)   \n",
    "        k2 = ds * x_prime\n",
    "\n",
    "        # Update position at the second midpoint.\n",
    "        x3 = x1 + .5 * k2\n",
    "    \n",
    "        loc = self._check_location(x3)[0]\n",
    "        if loc != \"IN\" or self.Interp_lambda_max(x3[1], x3[0])[0][0] < 1: \n",
    "            return None, None\n",
    "    \n",
    "        # Compute velocity at the second midpoint.\n",
    "        x_prime = self._differential_system_tensorlines_orientational_discontinuity(x3, x_prime)   \n",
    "        k3 = ds * x_prime\n",
    "    \n",
    "        # Update position at the endpoint.\n",
    "        x4 = x1 + k3\n",
    "    \n",
    "        loc = self._check_location(x4)[0]\n",
    "        if loc != \"IN\" or self.Interp_lambda_max(x4[1], x4[0])[0][0] < 1:\n",
    "            return None, None\n",
    "    \n",
    "        # Compute velocity at the end of the time-step.\n",
    "        x_prime = self._differential_system_tensorlines_orientational_discontinuity(x4, x_prime)    \n",
    "        k4 = ds * x_prime\n",
    "    \n",
    "        # define list for velocity and positions of particle\n",
    "        x_prime_update = []\n",
    "        x_update = []\n",
    "        \n",
    "        # Compute velocity\n",
    "        for j in range(self.dim):\n",
    "            # Update velocity of particles\n",
    "            x_prime_update.append(1.0 / 6.0*(k1[j] + 2 * k2[j] + 2 * k3[j] + k4[j])/ds)\n",
    "    \n",
    "        # Integration x <-- x + x_prime*ds\n",
    "        for j in range(self.dim):\n",
    "            # Update position of particles\n",
    "            x_update.append(x[j] + x_prime_update[j]*ds)\n",
    "\n",
    "        x_update = np.array(x_update)\n",
    "        x_prime_update = np.array(x_prime_update)\n",
    "        \n",
    "        if self._check_location(x_update)[0] != \"IN\" or self.Interp_lambda_max(x[1], x[0])[0][0] < 1: \n",
    "            return None, None\n",
    "    \n",
    "        return x_update, x_prime_update"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
