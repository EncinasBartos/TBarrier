{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Finite-Time-Lyapunov-Exponent-(FTLE)\" data-toc-modified-id=\"Finite-Time-Lyapunov-Exponent-(FTLE)-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Finite Time Lyapunov Exponent (FTLE)</a></span></li><li><span><a href=\"#Polar-Rotation-Angle-(PRA)\" data-toc-modified-id=\"Polar-Rotation-Angle-(PRA)-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Polar Rotation Angle (PRA)</a></span></li><li><span><a href=\"#Lagrangian-Averaged-Vorticity-Deviation-(LAVD)\" data-toc-modified-id=\"Lagrangian-Averaged-Vorticity-Deviation-(LAVD)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Lagrangian Averaged Vorticity Deviation (LAVD)</a></span></li><li><span><a href=\"#Quasi-Objective-Single-Trajectory-Rotation-Diagnostic\" data-toc-modified-id=\"Quasi-Objective-Single-Trajectory-Rotation-Diagnostic-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Quasi-Objective Single Trajectory Rotation Diagnostic</a></span><ul class=\"toc-item\"><li><span><a href=\"#Trajectory-Rotation-Average-(TRA)\" data-toc-modified-id=\"Trajectory-Rotation-Average-(TRA)-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Trajectory Rotation Average (TRA)</a></span></li><li><span><a href=\"#Trajectory-Rotation-Average-without-cancellations-$-(\\overline{TRA})-$\" data-toc-modified-id=\"Trajectory-Rotation-Average-without-cancellations-$-(\\overline{TRA})-$-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Trajectory Rotation Average without cancellations $ (\\overline{TRA}) $</a></span></li><li><span><a href=\"#Trajectory-Stretching-Exponent-$-(TSE)-$\" data-toc-modified-id=\"Trajectory-Stretching-Exponent-$-(TSE)-$-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Trajectory Stretching Exponent $ (TSE) $</a></span></li><li><span><a href=\"#Trajectory-Stretching-Exponent-without-cancellations-$-(\\overline{TSE})-$\" data-toc-modified-id=\"Trajectory-Stretching-Exponent-without-cancellations-$-(\\overline{TSE})-$-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Trajectory Stretching Exponent without cancellations $ (\\overline{TSE}) $</a></span></li></ul></li><li><span><a href=\"#Analytic-methods\" data-toc-modified-id=\"Analytic-methods-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Analytic methods</a></span><ul class=\"toc-item\"><li><span><a href=\"#Hyperbolic-LCS\" data-toc-modified-id=\"Hyperbolic-LCS-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Hyperbolic LCS</a></span><ul class=\"toc-item\"><li><span><a href=\"#Repelling/Attracting-LCS-as-shrinklines/strainlines-from-local-variational-theory\" data-toc-modified-id=\"Repelling/Attracting-LCS-as-shrinklines/strainlines-from-local-variational-theory-5.1.1\"><span class=\"toc-item-num\">5.1.1&nbsp;&nbsp;</span>Repelling/Attracting LCS as shrinklines/strainlines from local variational theory</a></span></li><li><span><a href=\"#Tensorlines--autonomous-differential-equation\" data-toc-modified-id=\"Tensorlines--autonomous-differential-equation-5.1.2\"><span class=\"toc-item-num\">5.1.2&nbsp;&nbsp;</span>Tensorlines- autonomous differential equation</a></span></li><li><span><a href=\"#Steady-Runge-Kutta-Integration-handling-orientational-discontinuities\" data-toc-modified-id=\"Steady-Runge-Kutta-Integration-handling-orientational-discontinuities-5.1.3\"><span class=\"toc-item-num\">5.1.3&nbsp;&nbsp;</span>Steady Runge-Kutta Integration handling orientational discontinuities</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T09:15:26.052074Z",
     "start_time": "2021-10-03T09:15:25.847264Z"
    }
   },
   "outputs": [],
   "source": [
    "# LCS\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "class LCS:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finite Time Lyapunov Exponent (FTLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T09:15:26.068031Z",
     "start_time": "2021-10-03T09:15:26.053071Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _FTLE_(self):\n",
    "        \n",
    "        if hasattr(self, 'C') == False:\n",
    "        \n",
    "            self._cauchy_green_strain()\n",
    "            \n",
    "        print(\"=================FTLE=================\")\n",
    "    \n",
    "        self.FTLE = np.zeros((self.len_Y, self.len_X, self.dim))*np.nan\n",
    "        \n",
    "        for i in range(self.len_Y):\n",
    "        \n",
    "            for j in range(self.len_X):\n",
    "                \n",
    "                lambda_min, lambda_max, v_min, v_max = self._eigenvalues_and_eigenvectors(self.C[i, j, :, :])\n",
    "                        \n",
    "                if lambda_min > 0:\n",
    "                    \n",
    "                    self.FTLE[i, j, 0] = 1/(2*(self.lenT))*np.log(lambda_min)\n",
    "                    self.FTLE[i, j, 1] = 1/(2*(self.lenT))*np.log(lambda_max)\n",
    "                        \n",
    "        return self.FTLE[:,:,0], self.FTLE[:,:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polar Rotation Angle (PRA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T09:15:26.083989Z",
     "start_time": "2021-10-03T09:15:26.069029Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _PRA_(self):\n",
    "            \n",
    "        if hasattr(self, 'grad_Fmap_grid') == False:\n",
    "        \n",
    "            self._grad_Fmap_grid()\n",
    "            \n",
    "        print(\"=================PRA=================\")\n",
    "            \n",
    "        self.PRA = np.zeros(self.X_domain.shape)\n",
    "            \n",
    "        for i in range(self.len_Y):\n",
    "        \n",
    "            for j in range(self.len_X):\n",
    "                \n",
    "                U, S, V = self._svd(self.grad_Fmap_grid[i, j, :, :])\n",
    "                \n",
    "                self.PRA[i, j] = np.arccos(U[0, 0]*V[0, 0]+U[0, 1]*V[0, 1])\n",
    "        \n",
    "        return self.PRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lagrangian Averaged Vorticity Deviation (LAVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T09:15:26.099456Z",
     "start_time": "2021-10-03T09:15:26.084986Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _LAVD_(self):\n",
    "        \n",
    "        if hasattr(self, 'trajectory_grid') == False:\n",
    "            \n",
    "            self._trajectory_grid()\n",
    "            \n",
    "        print(\"=================LAVD=================\")\n",
    "            \n",
    "        def parallelization(k, t):\n",
    "                \n",
    "            self.omega = self._vorticity(t)\n",
    "                \n",
    "            spatially_averaged_vorticity = np.nanmean(self.omega.ravel())\n",
    "                \n",
    "            LVD = np.zeros((self.len_Y, self.len_X))\n",
    "            \n",
    "            for i in range(self.len_Y):\n",
    "            \n",
    "                for j in range(self.len_X):\n",
    "                    \n",
    "                    x = np.array([self.trajectory_grid[i, j, 0, k], self.trajectory_grid[i, j, 1, k]]).reshape(1, -1)\n",
    "\n",
    "                    W = self._vorticity_tensor(x, t)\n",
    "                    \n",
    "                    omega = W[0, 1]-W[1, 0]\n",
    "                \n",
    "                    LVD[i, j] = np.abs(omega-spatially_averaged_vorticity)\n",
    "                    \n",
    "            return LVD\n",
    "        \n",
    "        self.LVD = np.array(Parallel(n_jobs=self.Ncores, verbose = 1)(delayed(parallelization)(k, t) for k, t in tqdm(enumerate(self.time), total=len(self.time))))\n",
    "        \n",
    "        self.LAVD = np.nanmean(self.LVD, axis = 0)\n",
    "        \n",
    "        return self.LAVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quasi-Objective Single Trajectory Rotation Diagnostic "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T09:08:30.992856Z",
     "start_time": "2021-10-03T09:08:30.982857Z"
    }
   },
   "source": [
    "## Trajectory Rotation Average (TRA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T09:15:26.115413Z",
     "start_time": "2021-10-03T09:15:26.100454Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _TRA_(self):\n",
    "        \n",
    "        if hasattr(self, 'trajectory_grid') == False:\n",
    "            \n",
    "            self._trajectory_grid()\n",
    "\n",
    "        print(\"=================TRA=================\")\n",
    "        \n",
    "        self.TRA = np.zeros((self.len_Y, self.len_X))\n",
    "            \n",
    "        for i in range(self.len_Y):\n",
    "            \n",
    "            for j in range(self.len_X):\n",
    "                    \n",
    "                velx0 = self.velocity_grid[i, j, 0, 0]\n",
    "                vely0 = self.velocity_grid[i, j, 1, 0]\n",
    "                    \n",
    "                vel0 = np.sqrt(velx0**2+vely0**2)\n",
    "                    \n",
    "                velxN = self.velocity_grid[i, j, 0, -1]\n",
    "                velyN = self.velocity_grid[i, j, 1, -1]\n",
    "                \n",
    "                vel1 = np.sqrt(velxN**2+velyN**2)\n",
    "                \n",
    "                self.TRA[i, j] = np.abs(np.arccos((velx0*velxN+vely0*velyN)/(vel0*vel1)))\n",
    "        \n",
    "        return self.TRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectory Rotation Average without cancellations $ (\\overline{TRA}) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T09:15:26.131369Z",
     "start_time": "2021-10-03T09:15:26.116412Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _TRA_bar_(self):\n",
    "        \n",
    "        if hasattr(self, 'trajectory_grid') == False:\n",
    "            \n",
    "            self._trajectory_grid()\n",
    "\n",
    "        print(\"=================TRA_bar=================\")\n",
    "        \n",
    "        self.TR_bar = np.zeros((self.len_Y, self.len_X, self.lenT-2))\n",
    "        \n",
    "        for k in tqdm(range(self.lenT-2), total = self.lenT-2):\n",
    "            \n",
    "            for i in range(self.len_Y):\n",
    "            \n",
    "                for j in range(self.len_X):\n",
    "                    \n",
    "                    velx0 = self.velocity_grid[i, j, 0, k]\n",
    "                    vely0 = self.velocity_grid[i, j, 1, k]\n",
    "                    \n",
    "                    vel0 = np.sqrt(velx0**2+vely0**2)\n",
    "                    \n",
    "                    velx1 = self.velocity_grid[i, j, 0, k + 1]\n",
    "                    vely1 = self.velocity_grid[i, j, 1, k + 1]\n",
    "                \n",
    "                    vel1 = np.sqrt(velx1**2+vely1**2)\n",
    "                \n",
    "                    self.TR_bar[i, j, k-1] = np.abs(np.arccos((velx0*velx1+vely0*vely1)/(vel0*vel1)))\n",
    "        \n",
    "        self.TRA_bar = np.nanmean(self.TR_bar, axis = 2)/(self.tN-self.t0)\n",
    "        \n",
    "        return self.TRA_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T09:10:21.602053Z",
     "start_time": "2021-10-03T09:10:21.591082Z"
    }
   },
   "source": [
    "## Trajectory Stretching Exponent $ (TSE) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T09:15:26.146329Z",
     "start_time": "2021-10-03T09:15:26.132367Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _TSE_(self):\n",
    "    \n",
    "        if hasattr(self, 'trajectory_grid') == False:\n",
    "            \n",
    "            self._trajectory_grid()\n",
    "\n",
    "        print(\"=================TSE=================\")\n",
    "        \n",
    "        self.TSE = np.zeros((self.len_Y, self.len_X))\n",
    "            \n",
    "        for i in range(self.len_Y):\n",
    "            \n",
    "            for j in range(self.len_X):\n",
    "                    \n",
    "                velx0 = self.velocity_grid[i, j, 0, 0]\n",
    "                vely0 = self.velocity_grid[i, j, 1, 0]\n",
    "                    \n",
    "                vel0 = np.sqrt(velx0**2+vely0**2)\n",
    "                    \n",
    "                velxN = self.velocity_grid[i, j, 0, -1]\n",
    "                velyN = self.velocity_grid[i, j, 1, -1]\n",
    "                \n",
    "                velN = np.sqrt(velxN**2+velyN**2)\n",
    "                \n",
    "                self.TSE[i, j] = 1/(self.tN-self.t0)*np.log(velN/vel0)\n",
    "        \n",
    "        return self.TSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectory Stretching Exponent without cancellations $ (\\overline{TSE}) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T09:15:26.161289Z",
     "start_time": "2021-10-03T09:15:26.147327Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _TSE_bar_(self):\n",
    "        \n",
    "        if hasattr(self, 'trajectory_grid') == False:\n",
    "            \n",
    "            self._trajectory_grid()\n",
    "\n",
    "        print(\"=================TSE_bar=================\")\n",
    "        \n",
    "        self.TSE_bar = np.zeros((self.len_Y, self.len_X, self.lenT-2))\n",
    "        \n",
    "        for k in tqdm(range(self.lenT-2), total = self.lenT-2):\n",
    "            \n",
    "            for i in range(self.len_Y):\n",
    "            \n",
    "                for j in range(self.len_X):\n",
    "                    \n",
    "                    velx0 = self.velocity_grid[i, j, 0, k]\n",
    "                    vely0 = self.velocity_grid[i, j, 1, k]\n",
    "                    \n",
    "                    vel0 = np.sqrt(velx0**2+vely0**2)\n",
    "                    \n",
    "                    velx1 = self.velocity_grid[i, j, 0, k + 1]\n",
    "                    vely1 = self.velocity_grid[i, j, 1, k + 1]\n",
    "                \n",
    "                    vel1 = np.sqrt(velx1**2+vely1**2)\n",
    "                \n",
    "                    self.TSE_bar[i, j, k] = np.abs(np.log(vel1/vel0))\n",
    "        \n",
    "        self.TSE_bar = np.nanmean(self.TSE_bar, axis = 2)/(self.tN-self.t0)\n",
    "        \n",
    "        return self.TRA_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytic methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperbolic LCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repelling/Attracting LCS as shrinklines/strainlines from local variational theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T09:15:26.193204Z",
     "start_time": "2021-10-03T09:15:26.162287Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _hyperbolic_LCS_local_variational_theory(self, max_distance = 1, type = \"shrinklines\", max_line_length = 10, step_size = None):\n",
    "        \n",
    "        if step_size is None:\n",
    "            step_size = self.dx/20\n",
    "        \n",
    "        self.lambda_max = np.zeros((self.len_Y, self.len_X))\n",
    "        self.eigenvector_max = np.zeros((self.len_Y, self.len_X, self.dim))\n",
    "        self.lambda_min = np.zeros((self.len_Y, self.len_X))\n",
    "        self.eigenvector_min = np.zeros((self.len_Y, self.len_X, self.dim))\n",
    "        \n",
    "        for i in range(self.len_Y):\n",
    "        \n",
    "            for j in range(self.len_X):\n",
    "        \n",
    "                lambda_min, lambda_max, v_min, v_max = self._eigenvalues_and_eigenvectors(self.C[i, j, :, :])\n",
    "        \n",
    "                if np.isfinite(lambda_max) and np.isfinite(lambda_min):\n",
    "                \n",
    "                    self.lambda_max[i, j] = lambda_max\n",
    "                    self.lambda_min[i, j] = lambda_min\n",
    "                    self.eigenvector_max[i, j, :] = v_max\n",
    "                    self.eigenvector_min[i, j, :] = v_min\n",
    "\n",
    "        if type == \"shrinklines\":\n",
    "    \n",
    "            self.eigen = self.eigenvector_min\n",
    "        \n",
    "            # Find local maxima of the max eigenvalue field\n",
    "            peak_x, peak_y, peak_field = self._find_2D_peaks(max_distance, self.X_domain, self.Y_domain, self.lambda_max)\n",
    "            \n",
    "        elif type == \"stretchlines\":\n",
    "    \n",
    "            self.eigen = self.eigenvector_max\n",
    "        \n",
    "            # Find local minima of the max eigenvalue field\n",
    "            peak_x, peak_y, peak_field = self._find_2D_peaks(max_distance, self.X_domain, self.Y_domain, -self.lambda_max)\n",
    "        \n",
    "        else:    \n",
    "            print(\"Variable type should either be shrinklines or stretchlines\")\n",
    "        \n",
    "        self.Interp_lambda_min = self._gridded_Interpolation(self.Y_domain, self.X_domain, self.lambda_min, \"cubic\")\n",
    "        self.Interp_lambda_max = self._gridded_Interpolation(self.Y_domain, self.X_domain, self.lambda_max, \"cubic\")\n",
    "        self.Interp_eigen_x = self._gridded_Interpolation(self.Y_domain, self.X_domain, self.eigen[:,:,0], \"cubic\")\n",
    "        self.Interp_eigen_y = self._gridded_Interpolation(self.Y_domain, self.X_domain, self.eigen[:,:,1], \"cubic\")\n",
    "    \n",
    "        x_tensorlines, y_tensorlines = [], []\n",
    "        \n",
    "        for i in tqdm(range(len(peak_x))):\n",
    "            \n",
    "            x_tensorline_forw, y_tensorline_forw = [], []\n",
    "            x_tensorline_back, y_tensorline_back = [], []\n",
    "            \n",
    "            x = np.array([peak_x[i], peak_y[i]])\n",
    "            bool_loc_max = True\n",
    "            \n",
    "            for j in range(len(x_tensorlines)):\n",
    "                \n",
    "                for k in range(len(x_tensorlines[j])):\n",
    "                    \n",
    "                    if np.sqrt((x[0]-x_tensorlines[j][k])**2+(x[1]-y_tensorlines[j][k])**2) < max_distance:\n",
    "                        bool_loc_max = False\n",
    "                        break\n",
    "            \n",
    "            x_forward_update = x\n",
    "            x_backward_update = x\n",
    "        \n",
    "            dist_forward = 0\n",
    "            dist_backward = 0\n",
    "            dist_total = 0\n",
    "        \n",
    "            counter = 0\n",
    "        \n",
    "            vx = self.Interp_eigen_x(x[1], x[0])[0][0]\n",
    "            vy = self.Interp_eigen_y(x[1], x[0])[0][0]\n",
    "            x_tensorline_forw.append(x[0])\n",
    "            y_tensorline_forw.append(x[1])\n",
    "                    \n",
    "            x_prime_forward = np.array([vx, vy])\n",
    "            x_prime_backward = -np.array([vx, vy])\n",
    "        \n",
    "            while dist_total <= max_line_length and bool_loc_max == True and counter < 1000:\n",
    "                    \n",
    "                if x_forward_update is not None:\n",
    "                \n",
    "                    if np.max(x_prime_forward) < 10**(-8):\n",
    "                    \n",
    "                        x_backward_update = None\n",
    "                    \n",
    "                    x_forward = x_forward_update\n",
    "                    x_forward_update, x_prime_forward = self._RK4_tensorlines_orientational_discontinuity(x_forward, x_prime_forward, step_size) \n",
    "                    if x_forward_update is not None:\n",
    "                        dist_forward = np.sqrt((x_forward_update[0]-x_forward[0])**2+(x_forward_update[1]-x_forward[1])**2)\n",
    "                \n",
    "                \n",
    "                if x_backward_update is not None:\n",
    "                    \n",
    "                    if np.max(x_prime_backward) < 10**(-8):\n",
    "                        x_backward_update = None\n",
    "                    \n",
    "                    x_backward = x_backward_update\n",
    "                    x_tensorline_back.append(x_backward[0])\n",
    "                    y_tensorline_back.append(x_backward[1])\n",
    "                    x_backward_update, x_prime_backward = self._RK4_tensorlines_orientational_discontinuity(x_backward, x_prime_backward, step_size)\n",
    "                    if x_backward_update is not None:\n",
    "                        dist_backward = np.sqrt((x_backward_update[0]-x_backward[0])**2+(x_backward_update[1]-x_backward[1])**2)\n",
    "                        \n",
    "                        \n",
    "                dist_total += dist_forward+dist_backward\n",
    "                dist_forward = 0\n",
    "                dist_backward = 0\n",
    "            \n",
    "                if x_forward_update is None and x_backward_update is None:\n",
    "                    bool_loc_max = False\n",
    "                \n",
    "                counter += 1\n",
    "            \n",
    "            x_tensorline = np.append(np.flip(x_tensorline_back), x_tensorline_forw)\n",
    "            y_tensorline = np.append(np.flip(y_tensorline_back), y_tensorline_forw)\n",
    "            x_tensorlines.append(x_tensorline)\n",
    "            y_tensorlines.append(y_tensorline)\n",
    "            \n",
    "        return x_tensorlines, y_tensorlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorlines- autonomous differential equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _differential_system_tensorlines_orientational_discontinuity(self, x, x_prime):\n",
    "                \n",
    "        # Check for orientational discontinuity by introducing appropriate scaling\n",
    "                \n",
    "        vx = self.Interp_eigen_x(x[1], x[0])[0][0]\n",
    "        vy = self.Interp_eigen_y(x[1], x[0])[0][0]\n",
    "            \n",
    "        lambda_max = self.Interp_lambda_max(x[1], x[0])[0][0]\n",
    "        lambda_min = self.Interp_lambda_min(x[1], x[0])[0][0]\n",
    "            \n",
    "        alpha = ((lambda_max-lambda_min)/(lambda_max+lambda_min))**2\n",
    "            \n",
    "        scaling = np.sign(vx*x_prime[0]+vy*x_prime[1])*alpha\n",
    "            \n",
    "        return scaling*np.array([vx, vy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steady Runge-Kutta Integration handling orientational discontinuities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _RK4_tensorlines_orientational_discontinuity(self, x, x_prime, ds):\n",
    "        \n",
    "        # Define starting point.\n",
    "        x1 = x\n",
    "        \n",
    "        # If x is outside defined domain --> vel is None --> _RK4 returns \"None\" and integration will stop.\n",
    "            \n",
    "        # Compute x_prime at the beginning of the time-step\n",
    "        \n",
    "        loc = self._check_location(x1)[0]\n",
    "        \n",
    "        if loc != \"IN\" or self.Interp_lambda_max(x1[1], x1[0])[0][0] < 1:\n",
    "            return None, None\n",
    "        x_prime = self._differential_system_tensorlines_orientational_discontinuity(x1, x_prime)  \n",
    "        k1 = ds * x_prime\n",
    "\n",
    "        #  position and time at the first midpoint.\n",
    "        x2 = x1 + .5 * k1\n",
    "        loc = self._check_location(x2)[0]\n",
    "        \n",
    "        if loc != \"IN\" or self.Interp_lambda_max(x2[1], x2[0])[0][0] < 1:\n",
    "            return None, None\n",
    "        \n",
    "        # Compute x_prime at the first midpoint.\n",
    "        x_prime = self._differential_system_tensorlines_orientational_discontinuity(x2, x_prime)   \n",
    "        k2 = ds * x_prime\n",
    "\n",
    "        # Update position at the second midpoint.\n",
    "        x3 = x1 + .5 * k2\n",
    "    \n",
    "        loc = self._check_location(x3)[0]\n",
    "        if loc != \"IN\" or self.Interp_lambda_max(x3[1], x3[0])[0][0] < 1: \n",
    "            return None, None\n",
    "    \n",
    "        # Compute velocity at the second midpoint.\n",
    "        x_prime = self._differential_system_tensorlines_orientational_discontinuity(x3, x_prime)   \n",
    "        k3 = ds * x_prime\n",
    "    \n",
    "        # Update position at the endpoint.\n",
    "        x4 = x1 + k3\n",
    "    \n",
    "        loc = self._check_location(x4)[0]\n",
    "        if loc != \"IN\" or self.Interp_lambda_max(x4[1], x4[0])[0][0] < 1:\n",
    "            return None, None\n",
    "    \n",
    "        # Compute velocity at the end of the time-step.\n",
    "        x_prime = self._differential_system_tensorlines_orientational_discontinuity(x4, x_prime)    \n",
    "        k4 = ds * x_prime\n",
    "    \n",
    "        # define list for velocity and positions of particle\n",
    "        x_prime_update = []\n",
    "        x_update = []\n",
    "        \n",
    "        # Compute velocity\n",
    "        for j in range(self.dim):\n",
    "            # Update velocity of particles\n",
    "            x_prime_update.append(1.0 / 6.0*(k1[j] + 2 * k2[j] + 2 * k3[j] + k4[j])/ds)\n",
    "    \n",
    "        # Integration x <-- x + x_prime*ds\n",
    "        for j in range(self.dim):\n",
    "            # Update position of particles\n",
    "            x_update.append(x[j] + x_prime_update[j]*ds)\n",
    "\n",
    "        x_update = np.array(x_update)\n",
    "        x_prime_update = np.array(x_prime_update)\n",
    "        \n",
    "        if self._check_location(x_update)[0] != \"IN\" or self.Interp_lambda_max(x[1], x[0])[0][0] < 1: \n",
    "            return None, None\n",
    "    \n",
    "        return x_update, x_prime_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T09:15:26.208669Z",
     "start_time": "2021-10-03T09:15:26.194202Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _elliptic_LCS_local_variational_theory(self):\n",
    "        \n",
    "        print(\"=================Elliptic LCS from local variational theory=================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T09:15:26.224626Z",
     "start_time": "2021-10-03T09:15:26.209667Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _hyperbolic_LCS_global_variational_theory(self):\n",
    "        \n",
    "        print(\"=================Hyperbolic LCS from global variational theory=================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T09:15:26.240611Z",
     "start_time": "2021-10-03T09:15:26.225624Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _elliptic_LCS_global_variational_theory(self):\n",
    "        \n",
    "        print(\"=================Elliptic LCS from global variational theory=================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T09:15:26.256569Z",
     "start_time": "2021-10-03T09:15:26.241583Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _vorticity(self, t):\n",
    "        \n",
    "        self.omega = np.zeros((self.len_Y, self.len_X))\n",
    "        \n",
    "        for i in range(self.len_Y):\n",
    "            \n",
    "            for j in range(self.len_X):\n",
    "                \n",
    "                x = np.array([self.X_domain[i, j], self.Y_domain[i, j]]).reshape(1, -1)\n",
    "    \n",
    "                W = self._vorticity_tensor(x, t)\n",
    "                \n",
    "                self.omega[i, j] = W[0, 1]-W[1, 0]\n",
    "                \n",
    "        return self.omega              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T09:15:26.272535Z",
     "start_time": "2021-10-03T09:15:26.257540Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _find_ridges(self, Field, threshold = None, type = \"ridge\", method = \"threshold\", resolution = 1, ds = 1, n_iterations = 100):\n",
    "        \n",
    "        if type == \"ridge\":\n",
    "            \n",
    "            sign = 1\n",
    "            \n",
    "            if threshold is None:\n",
    "            \n",
    "                print(\"Threshold value is None --> Specify threshold.\")\n",
    "                print(\"If not specified, threshold is set to \", 0.1, \" of the maximum value of the given scalar field\")\n",
    "            \n",
    "                threshold = .1*np.nanmax(Field)\n",
    "            \n",
    "        elif type == \"trench\":\n",
    "            \n",
    "            sign = -1\n",
    "                  \n",
    "            if threshold is None:\n",
    "            \n",
    "                print(\"Threshold value is None --> Specify threshold.\")\n",
    "                print(\"If not specified, threshold is set to \", 0.1, \" of the maximum value of the given scalar field\")\n",
    "            \n",
    "                threshold = .1*np.nanmin(Field)\n",
    "            \n",
    "        if method == \"threshold\":\n",
    "            \n",
    "            mask = (Field >= threshold)\n",
    "            \n",
    "            extrema_x = self.X_domain[mask].ravel()\n",
    "            extrema_y = self.Y_domain[mask].ravel()\n",
    "            \n",
    "            return extrema_x, extrema_y\n",
    "            \n",
    "        elif method == \"gradient\":\n",
    "            \n",
    "            Field[np.isnan(Field)] = 0\n",
    "            \n",
    "            Interpolant_Field = self._Interpolation(self.Y_domain, self.X_domain, Field, method = \"cubic\")\n",
    "            \n",
    "            grad_Field = np.zeros((Field.shape[0], Field.shape[1], 2))\n",
    "            \n",
    "            for i in range(1, Field.shape[0]-1):\n",
    "                \n",
    "                for j in range(1, Field.shape[1]-1):\n",
    "                    \n",
    "                    dy = (self.Y_domain[i+1,0] - self.Y_domain[i-1, 0])/2\n",
    "                    dx = (self.X_domain[0, j+1] - self.X_domain[0, j-1])/2\n",
    "\n",
    "                    grad_Field[i, j, 0] = (Interpolant_Field(self.Y_domain[i, j], self.X_domain[i, j]+.1*dx)[0][0]-Interpolant_Field(self.Y_domain[i, j], self.X_domain[i, j]-.1*dx)[0][0])/(2*.1*dx)\n",
    "                    grad_Field[i, j, 1] = (Interpolant_Field(self.Y_domain[i, j]+.1*dy, self.X_domain[i, j])[0][0]-Interpolant_Field(self.Y_domain[i, j]-.1*dy, self.X_domain[i, j])[0][0])/(2*.1*dy)\n",
    "        \n",
    "            grad_Fieldx = grad_Field[:, :, 0]\n",
    "            grad_Fieldy = grad_Field[:, :, 1]\n",
    "            grad_Fieldx[np.isnan(grad_Fieldx)] = 0\n",
    "            grad_Fieldy[np.isnan(grad_Fieldy)] = 0\n",
    "            \n",
    "            Interpolant_gradx_Field = self._Interpolation(self.Y_domain, self.X_domain, grad_Fieldx)\n",
    "            Interpolant_grady_Field = self._Interpolation(self.Y_domain, self.X_domain, grad_Fieldy)\n",
    "            \n",
    "            x_grid = np.linspace(np.min(self.X_domain), np.max(self.X_domain), self.Y_domain.shape[0]*resolution)\n",
    "            y_grid = np.linspace(np.min(self.Y_domain), np.max(self.Y_domain), self.Y_domain.shape[1]*resolution)\n",
    "            \n",
    "            extrema_x = []\n",
    "            extrema_y = []\n",
    "            \n",
    "            for x in tqdm(x_grid, total = len(x_grid)):\n",
    "                    \n",
    "                for y in y_grid:\n",
    "                    \n",
    "                    x_eval = x\n",
    "                    y_eval = y\n",
    "    \n",
    "                    loc = self._check_location(np.array([x_eval, y_eval]).reshape(1, -1))[0]\n",
    "                        \n",
    "                    gradient = 10\n",
    "                    \n",
    "                    iter = 0\n",
    "                        \n",
    "                    while iter < n_iterations and loc == \"IN\" and Interpolant_Field(y_eval, x_eval)[0][0] > threshold:\n",
    "                            \n",
    "                        loc = self._check_location(np.array([x_eval, y_eval]).reshape(1, -1))[0]\n",
    "                        \n",
    "                        gradx = Interpolant_gradx_Field(y_eval, x_eval)[0][0]\n",
    "                        grady = Interpolant_grady_Field(y_eval, x_eval)[0][0]\n",
    "                        \n",
    "                        gradient = np.sqrt(gradx**2+grady**2)\n",
    "                        \n",
    "                        x_eval = x_eval + sign * ds * gradx/gradient*dx\n",
    "                        y_eval = y_eval + sign * ds * grady/gradient*dy\n",
    "                        \n",
    "                        iter += 1\n",
    "                    \n",
    "                        extrema_x.append(x_eval)\n",
    "                        extrema_y.append(y_eval)\n",
    "            \n",
    "            return extrema_x, extrema_y\n",
    "\n",
    "        else:\n",
    "            \n",
    "            print(\"The method argument is not valid. Use either threshold or gradient\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T09:15:26.287458Z",
     "start_time": "2021-10-03T09:15:26.273523Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _find_2D_peaks(self, max_distance, X, Y, Field):\n",
    "        \n",
    "        def _find_all_local_maxima(X, Y, Field):\n",
    "            \n",
    "            loc_max_x, loc_max_y, loc_max_field = [], [], []\n",
    "            \n",
    "            for i in tqdm(range(2, X.shape[0]-2)):\n",
    "                \n",
    "                for j in range(2, Y.shape[1]-2):\n",
    "                    \n",
    "                    if np.isfinite(Field[i, j]) and Field[i, j] > Field[i+1, j] and Field[i, j] > Field[i-1, j] and Field[i, j] > Field[i, j+1] and Field[i, j] > Field[i, j-1]:\n",
    "                        \n",
    "                        loc_max_x.append(X[i, j])\n",
    "                        loc_max_y.append(Y[i, j])\n",
    "                        loc_max_field.append(Field[i, j])\n",
    "            \n",
    "            return loc_max_x, loc_max_y, loc_max_field\n",
    "        \n",
    "        loc_max_x, loc_max_y, loc_max_field = _find_all_local_maxima(X, Y, Field)\n",
    "        \n",
    "        n_loc_max = len(loc_max_x)\n",
    "        \n",
    "        peak_x, peak_y, peak_field = [], [], []\n",
    "        \n",
    "        for i in range(n_loc_max):\n",
    "            \n",
    "            bool_loc_max = True\n",
    "    \n",
    "            for j in range(n_loc_max):\n",
    "            \n",
    "                if i != j and loc_max_field[i] < loc_max_field[j] and np.sqrt((loc_max_x[i]-loc_max_x[j])**2+(loc_max_y[i]-loc_max_y[j])**2) <= max_distance:\n",
    "                    \n",
    "                    bool_loc_max = False\n",
    "                \n",
    "            if bool_loc_max:\n",
    "                \n",
    "                peak_x.append(loc_max_x[i])\n",
    "                peak_y.append(loc_max_y[i])\n",
    "                peak_field.append(loc_max_field[i])\n",
    "                \n",
    "        return peak_x, peak_y, peak_field"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "245.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
