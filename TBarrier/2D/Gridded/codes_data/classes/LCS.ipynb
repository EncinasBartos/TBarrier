{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Diagnostic-methods\" data-toc-modified-id=\"Diagnostic-methods-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Diagnostic methods</a></span><ul class=\"toc-item\"><li><span><a href=\"#Finite-Time-Lyapunov-Exponent-(FTLE)\" data-toc-modified-id=\"Finite-Time-Lyapunov-Exponent-(FTLE)-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Finite Time Lyapunov Exponent (FTLE)</a></span></li><li><span><a href=\"#Polar-Rotation-Angle-(PRA)\" data-toc-modified-id=\"Polar-Rotation-Angle-(PRA)-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Polar Rotation Angle (PRA)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Lagrangian-vortex-boundary-from-PRA\" data-toc-modified-id=\"Lagrangian-vortex-boundary-from-PRA-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Lagrangian vortex boundary from PRA</a></span></li></ul></li><li><span><a href=\"#Lagrangian-Averaged-Vorticity-Deviation-(LAVD)\" data-toc-modified-id=\"Lagrangian-Averaged-Vorticity-Deviation-(LAVD)-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Lagrangian Averaged Vorticity Deviation (LAVD)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Lagrangian-vortex-boundary-from-LAVD\" data-toc-modified-id=\"Lagrangian-vortex-boundary-from-LAVD-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Lagrangian vortex boundary from LAVD</a></span></li></ul></li><li><span><a href=\"#Quasi-Objective-diagnostics\" data-toc-modified-id=\"Quasi-Objective-diagnostics-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Quasi-Objective diagnostics</a></span><ul class=\"toc-item\"><li><span><a href=\"#Trajectory-Rotation-Average-(TRA)\" data-toc-modified-id=\"Trajectory-Rotation-Average-(TRA)-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>Trajectory Rotation Average (TRA)</a></span></li><li><span><a href=\"#Trajectory-Rotation-Average-without-cancellations-$-(\\overline{TRA})-$\" data-toc-modified-id=\"Trajectory-Rotation-Average-without-cancellations-$-(\\overline{TRA})-$-1.4.2\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;</span>Trajectory Rotation Average without cancellations $ (\\overline{TRA}) $</a></span></li><li><span><a href=\"#Trajectory-Stretching-Exponent-$-(TSE)-$\" data-toc-modified-id=\"Trajectory-Stretching-Exponent-$-(TSE)-$-1.4.3\"><span class=\"toc-item-num\">1.4.3&nbsp;&nbsp;</span>Trajectory Stretching Exponent $ (TSE) $</a></span></li><li><span><a href=\"#Trajectory-Stretching-Exponent-without-cancellations-$-(\\overline{TSE})-$\" data-toc-modified-id=\"Trajectory-Stretching-Exponent-without-cancellations-$-(\\overline{TSE})-$-1.4.4\"><span class=\"toc-item-num\">1.4.4&nbsp;&nbsp;</span>Trajectory Stretching Exponent without cancellations $ (\\overline{TSE}) $</a></span></li></ul></li></ul></li><li><span><a href=\"#Analytic-methods\" data-toc-modified-id=\"Analytic-methods-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Analytic methods</a></span><ul class=\"toc-item\"><li><span><a href=\"#Hyperbolic-LCS\" data-toc-modified-id=\"Hyperbolic-LCS-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Hyperbolic LCS</a></span><ul class=\"toc-item\"><li><span><a href=\"#Hyperbolic-LCS-from-local-variational-theory\" data-toc-modified-id=\"Hyperbolic-LCS-from-local-variational-theory-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Hyperbolic LCS from local variational theory</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tensorlines---autonomous-differential-equation\" data-toc-modified-id=\"Tensorlines---autonomous-differential-equation-2.1.1.1\"><span class=\"toc-item-num\">2.1.1.1&nbsp;&nbsp;</span>Tensorlines - autonomous differential equation</a></span></li><li><span><a href=\"#Orientational-discontinuity\" data-toc-modified-id=\"Orientational-discontinuity-2.1.1.2\"><span class=\"toc-item-num\">2.1.1.2&nbsp;&nbsp;</span>Orientational discontinuity</a></span></li><li><span><a href=\"#Steady-$-4^{th}-$-order-Runge---Kutta-Integration-handling-orientational-discontinuities\" data-toc-modified-id=\"Steady-$-4^{th}-$-order-Runge---Kutta-Integration-handling-orientational-discontinuities-2.1.1.3\"><span class=\"toc-item-num\">2.1.1.3&nbsp;&nbsp;</span>Steady $ 4^{th} $-order Runge - Kutta Integration handling orientational discontinuities</a></span></li></ul></li></ul></li><li><span><a href=\"#Elliptic-LCS\" data-toc-modified-id=\"Elliptic-LCS-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Elliptic LCS</a></span><ul class=\"toc-item\"><li><span><a href=\"#Elliptic-LCS-from-local-variational-theory\" data-toc-modified-id=\"Elliptic-LCS-from-local-variational-theory-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Elliptic LCS from local variational theory</a></span></li><li><span><a href=\"#Numerical-detection-of-singularities\" data-toc-modified-id=\"Numerical-detection-of-singularities-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Numerical detection of singularities</a></span></li><li><span><a href=\"#Poincare-section\" data-toc-modified-id=\"Poincare-section-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>Poincare section</a></span></li></ul></li></ul></li><li><span><a href=\"#General-functions\" data-toc-modified-id=\"General-functions-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>General functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Ridge-extraction\" data-toc-modified-id=\"Ridge-extraction-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Ridge extraction</a></span></li><li><span><a href=\"#Local-extrema\" data-toc-modified-id=\"Local-extrema-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Local extrema</a></span></li><li><span><a href=\"#Contourlines\" data-toc-modified-id=\"Contourlines-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Contourlines</a></span></li><li><span><a href=\"#Area-of-polygon\" data-toc-modified-id=\"Area-of-polygon-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Area of polygon</a></span></li><li><span><a href=\"#Convexity-deficiency\" data-toc-modified-id=\"Convexity-deficiency-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Convexity deficiency</a></span></li><li><span><a href=\"#Point-inside-polygon\" data-toc-modified-id=\"Point-inside-polygon-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Point inside polygon</a></span></li><li><span><a href=\"#Length-closed-material-line\" data-toc-modified-id=\"Length-closed-material-line-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>Length closed material line</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T08:50:34.406821Z",
     "start_time": "2021-10-12T08:50:34.266857Z"
    }
   },
   "outputs": [],
   "source": [
    "# LCS\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "class LCS:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Diagnostic_methods'></a>\n",
    "# Diagnostic methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='FTLE'></a>\n",
    "## Finite Time Lyapunov Exponent (FTLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Finite Time Lyapunov Exponent (FTLE) is computed from the eigenvalues $ \\lambda_i $ of the Cauchy-Green strain tensor $ C_{t_0}^{t_1}(\\mathbf{x}_0) $:\n",
    "\n",
    "\\begin{equation}\n",
    "FTLE = \\dfrac{1}{2(t_1-t_0)}\\log(\\lambda_i), \\quad i = 1, 2 \n",
    "\\end{equation}\n",
    "\n",
    "where $ \\lambda_i $ denotes the eigenvalue associated with the eigenvector $ \\mathbf{\\xi}_i(\\mathbf{x}_0; t_0, t_1) $ of $ C_{t_0}^{t_1}(\\mathbf{x}_0) $.\n",
    "The minimum FTLE is computed for $ i = 1 $ (weakest eigenvalue), whereas the maximum FTLE is computed by setting $ i = 2 $ (dominant eigenvalue). If the type (minimum/maximum) of the FTLE is not specified, then we always assume that we are dealing with the maximum FTLE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T08:50:34.422778Z",
     "start_time": "2021-10-12T08:50:34.407818Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _FTLE_(self):\n",
    "        \n",
    "        if hasattr(self, 'C') == False:\n",
    "        \n",
    "            self._cauchy_green_strain()\n",
    "    \n",
    "        self.FTLE_min = np.zeros((self.len_Y, self.len_X))*np.nan\n",
    "        self.FTLE_max = np.zeros((self.len_Y, self.len_X))*np.nan\n",
    "        \n",
    "        for i in range(self.len_Y):\n",
    "        \n",
    "            for j in range(self.len_X):\n",
    "                \n",
    "                lambda_min, lambda_max, v_min, v_max = self._eigenvalues_and_eigenvectors(self.C[i, j, :, :])\n",
    "                    \n",
    "                self.FTLE_min[i, j] = 1/(2*(self.lenT))*np.log(lambda_min)\n",
    "                self.FTLE_max[i, j] = 1/(2*(self.lenT))*np.log(lambda_max)\n",
    "                        \n",
    "        return self.FTLE_min, self.FTLE_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='PRA'></a>\n",
    "## Polar Rotation Angle (PRA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Polar Rotation Angle (PRA) is computed from the eigenvectors $ \\xi_i, \\eta_i $ (with i = 1, 2) of the Cauchy-Green strain tensor $ C_{t_0}^{t_1}(\\mathbf{x}_0) $:\n",
    "\n",
    "\\begin{equation}\n",
    "PRA_{t_0}^{t_1}(\\mathbf{x}_0) = \\langle \\xi_1(\\mathbf{x}_0;t_0, t_1), \\eta_1(\\mathbf{x}_0;t_0, t_1) \\rangle = \\langle \\xi_2(\\mathbf{x}_0;t_0, t_1), \\eta_2(\\mathbf{x}_0;t_0, t_1) \\rangle\n",
    "\\end{equation}\n",
    "\n",
    "As the maximum eigenvalue is less sensitive with respect to numerical errors, it is recommended to use the dominant eigenvectors $ \\xi_2, \\eta_2 $ in order to compute $ PRA_{t_0}^{t_1}(\\mathbf{x}_0) $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T08:50:34.438736Z",
     "start_time": "2021-10-12T08:50:34.423776Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _PRA_(self):\n",
    "            \n",
    "        if hasattr(self, 'grad_Fmap_grid') == False:\n",
    "        \n",
    "            self._grad_Fmap_grid()\n",
    "            \n",
    "        self.PRA = np.zeros(self.X_domain.shape)\n",
    "            \n",
    "        for i in range(self.len_Y):\n",
    "        \n",
    "            for j in range(self.len_X):\n",
    "                \n",
    "                U, S, V = self._svd(self.grad_Fmap_grid[i, j, :, :])\n",
    "                \n",
    "                self.PRA[i, j] = np.arccos(U[0, 0]*V[0, 0]+U[0, 1]*V[0, 1])\n",
    "        \n",
    "        return self.PRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='LAVD'></a>\n",
    "### Lagrangian vortex boundary from PRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T08:50:34.454784Z",
     "start_time": "2021-10-12T08:50:34.439733Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _vortex_boundary_and_center_from_PRA(self, n_contours = 100, max_distance = .5, convexity_threshold = 10**(-5), length_threshold = .5):\n",
    "        \n",
    "        contours = self._contourlines(self.X_domain, self.Y_domain, self.PRA, n_contours)\n",
    "        x_max, y_max, LAVD_max = self._find_2D_peaks(max_distance, self.X_domain, self.Y_domain, self.PRA)\n",
    "        \n",
    "        vortex_boundary = []\n",
    "        vortex_center_x, vortex_center_y = [], []\n",
    "        \n",
    "        for i in range(len(x_max)):\n",
    "            \n",
    "            tubular_surfaces = []\n",
    "            length_tubes = []\n",
    "            vortex_center_x_candidate, vortex_center_y_candidate = [], []\n",
    "            \n",
    "            for c in contours:\n",
    "            \n",
    "                bool_contour = self._point_inside_polygon(x_max[i], y_max[i], c)\n",
    "                \n",
    "                if bool_contour:\n",
    "                    \n",
    "                    convexity_deficiency = self._convexity_deficiency(c)\n",
    "                    length = self._length_closed_material_line(c)\n",
    "                    \n",
    "                    if convexity_deficiency < convexity_threshold and length > length_threshold:\n",
    "                        \n",
    "                        tubular_surfaces.append(c)\n",
    "                        length_tubes.append(length)\n",
    "                        vortex_center_x_candidate.append(x_max[i])\n",
    "                        vortex_center_y_candidate.append(y_max[i])\n",
    "            \n",
    "            if len(length_tubes) > 0:           \n",
    "                argmax_length = np.argmax(length_tubes)\n",
    "                vortex_boundary.append(tubular_surfaces[argmax_length])\n",
    "                vortex_center_x.append(vortex_center_x_candidate[argmax_length])\n",
    "                vortex_center_y.append(vortex_center_y_candidate[argmax_length])           \n",
    "\n",
    "        return vortex_boundary, vortex_center_x, vortex_center_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lagrangian Averaged Vorticity Deviation (LAVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T08:50:34.470759Z",
     "start_time": "2021-10-12T08:50:34.455752Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _LAVD(self):\n",
    "        \n",
    "        if hasattr(self, 'trajectory_grid') == False:\n",
    "            \n",
    "            self._trajectory_grid()\n",
    "            \n",
    "        def parallelization(k, t):\n",
    "                \n",
    "            self.omega = self._vorticity(t)\n",
    "                \n",
    "            spatially_averaged_vorticity = np.nanmean(self.omega.ravel())  \n",
    "                \n",
    "            LVD = np.zeros((self.len_Y, self.len_X))\n",
    "            \n",
    "            for i in range(self.len_Y):\n",
    "            \n",
    "                for j in range(self.len_X):\n",
    "                    \n",
    "                    x = np.array([self.trajectory_grid[i, j, 0, k], self.trajectory_grid[i, j, 1, k]])\n",
    "\n",
    "                    W = self._vorticity_tensor(x, t)\n",
    "                    \n",
    "                    omega = W[0, 1]-W[1, 0]\n",
    "                \n",
    "                    LVD[i, j] = np.abs(omega-spatially_averaged_vorticity)\n",
    "                    \n",
    "            return LVD\n",
    "        \n",
    "        self.LVD = np.array(Parallel(n_jobs=self.Ncores, verbose = 1)(delayed(parallelization)(k, t) for k, t in tqdm(enumerate(self.time), total=self.lenT)))\n",
    "        \n",
    "        self.LAVD = np.nanmean(self.LVD, axis = 0)\n",
    "        \n",
    "        return self.LAVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lagrangian vortex boundary from LAVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T08:50:34.486698Z",
     "start_time": "2021-10-12T08:50:34.471771Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _vortex_boundary_and_center_from_LAVD(self, n_contours = 100, max_distance = .5, convexity_threshold = 10**(-5), length_threshold = .5):\n",
    "        \n",
    "        contours = self._contourlines(self.X_domain, self.Y_domain, self.LAVD, n_contours)\n",
    "        x_max, y_max, LAVD_max = self._find_2D_peaks(max_distance, self.X_domain, self.Y_domain, self.LAVD)\n",
    "        \n",
    "        vortex_boundary = []\n",
    "        vortex_center_x, vortex_center_y = [], []\n",
    "        \n",
    "        for i in range(len(x_max)):\n",
    "            \n",
    "            tubular_surfaces = []\n",
    "            length_tubes = []\n",
    "            vortex_center_x_candidate, vortex_center_y_candidate = [], []\n",
    "            \n",
    "            for c in contours:\n",
    "            \n",
    "                bool_contour = self._point_inside_polygon(x_max[i], y_max[i], c)\n",
    "                \n",
    "                if bool_contour:\n",
    "                    \n",
    "                    convexity_deficiency = self._convexity_deficiency(c)\n",
    "                    length = self._length_closed_material_line(c)\n",
    "                    \n",
    "                    if convexity_deficiency < convexity_threshold and length > length_threshold:\n",
    "                        \n",
    "                        tubular_surfaces.append(c)\n",
    "                        length_tubes.append(length)\n",
    "                        vortex_center_x_candidate.append(x_max[i])\n",
    "                        vortex_center_y_candidate.append(y_max[i])\n",
    "            \n",
    "            if len(length_tubes) > 0:           \n",
    "                argmax_length = np.argmax(length_tubes)\n",
    "                vortex_boundary.append(tubular_surfaces[argmax_length])\n",
    "                vortex_center_x.append(vortex_center_x_candidate[argmax_length])\n",
    "                vortex_center_y.append(vortex_center_y_candidate[argmax_length])      \n",
    "\n",
    "        return vortex_boundary, vortex_center_x, vortex_center_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Quasi_objective_diagnostics'></a>\n",
    "## Quasi-Objective diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T09:08:30.992856Z",
     "start_time": "2021-10-03T09:08:30.982857Z"
    }
   },
   "source": [
    "<a id='TRA'></a>\n",
    "### Trajectory Rotation Average (TRA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T08:50:34.502656Z",
     "start_time": "2021-10-12T08:50:34.487697Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _TRA_(self):\n",
    "        \n",
    "        if hasattr(self, 'trajectory_grid') == False:\n",
    "            \n",
    "            self._trajectory_grid()\n",
    "        \n",
    "        self.TRA = np.zeros((self.len_Y, self.len_X))\n",
    "            \n",
    "        for i in range(self.len_Y):\n",
    "            \n",
    "            for j in range(self.len_X):\n",
    "                    \n",
    "                velx0 = self.velocity_grid[i, j, 0, 0]\n",
    "                vely0 = self.velocity_grid[i, j, 1, 0]\n",
    "                    \n",
    "                vel0 = np.sqrt(velx0**2+vely0**2)\n",
    "                    \n",
    "                velxN = self.velocity_grid[i, j, 0, -1]\n",
    "                velyN = self.velocity_grid[i, j, 1, -1]\n",
    "                \n",
    "                vel1 = np.sqrt(velxN**2+velyN**2)\n",
    "                \n",
    "                self.TRA[i, j] = np.abs(np.arccos((velx0*velxN+vely0*velyN)/(vel0*vel1)))\n",
    "        \n",
    "        return self.TRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='TRA_bar'></a>\n",
    "### Trajectory Rotation Average without cancellations $ (\\overline{TRA}) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T08:50:34.518613Z",
     "start_time": "2021-10-12T08:50:34.503653Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _TRA_bar_(self):\n",
    "        \n",
    "        if hasattr(self, 'trajectory_grid') == False:\n",
    "            \n",
    "            self._trajectory_grid()\n",
    "        \n",
    "        self.TR_bar = np.zeros((self.len_Y, self.len_X, self.lenT-2))\n",
    "        \n",
    "        for k in tqdm(range(self.lenT-2), total = self.lenT-2):\n",
    "            \n",
    "            for i in range(self.len_Y):\n",
    "            \n",
    "                for j in range(self.len_X):\n",
    "                    \n",
    "                    velx0 = self.velocity_grid[i, j, 0, k]\n",
    "                    vely0 = self.velocity_grid[i, j, 1, k]\n",
    "                    \n",
    "                    vel0 = np.sqrt(velx0**2+vely0**2)\n",
    "                    \n",
    "                    velx1 = self.velocity_grid[i, j, 0, k + 1]\n",
    "                    vely1 = self.velocity_grid[i, j, 1, k + 1]\n",
    "                \n",
    "                    vel1 = np.sqrt(velx1**2+vely1**2)\n",
    "                \n",
    "                    self.TR_bar[i, j, k-1] = np.abs(np.arccos((velx0*velx1+vely0*vely1)/(vel0*vel1)))\n",
    "        \n",
    "        self.TRA_bar = np.nanmean(self.TR_bar, axis = 2)/(self.tN-self.t0)\n",
    "        \n",
    "        return self.TRA_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='TSE'></a>\n",
    "### Trajectory Stretching Exponent $ (TSE) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T08:50:34.533573Z",
     "start_time": "2021-10-12T08:50:34.519611Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _TSE_(self):\n",
    "    \n",
    "        if hasattr(self, 'trajectory_grid') == False:\n",
    "            \n",
    "            self._trajectory_grid()\n",
    "        \n",
    "        self.TSE = np.zeros((self.len_Y, self.len_X))\n",
    "            \n",
    "        for i in range(self.len_Y):\n",
    "            \n",
    "            for j in range(self.len_X):\n",
    "                    \n",
    "                velx0 = self.velocity_grid[i, j, 0, 0]\n",
    "                vely0 = self.velocity_grid[i, j, 1, 0]\n",
    "                    \n",
    "                vel0 = np.sqrt(velx0**2+vely0**2)\n",
    "                    \n",
    "                velxN = self.velocity_grid[i, j, 0, -1]\n",
    "                velyN = self.velocity_grid[i, j, 1, -1]\n",
    "                \n",
    "                velN = np.sqrt(velxN**2+velyN**2)\n",
    "                \n",
    "                self.TSE[i, j] = 1/(self.tN-self.t0)*np.log(velN/vel0)\n",
    "        \n",
    "        return self.TSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='TSE_bar'></a>\n",
    "### Trajectory Stretching Exponent without cancellations $ (\\overline{TSE}) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T08:50:34.548535Z",
     "start_time": "2021-10-12T08:50:34.534571Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _TSE_bar_(self):\n",
    "        \n",
    "        if hasattr(self, 'trajectory_grid') == False:\n",
    "            \n",
    "            raise Exception(\"You need to calculate trajectories over meshgrid and then compute velocity using finite differencing!\")\n",
    "        \n",
    "        self.TSE_bar = np.zeros((self.len_Y, self.len_X, self.lenT-2))\n",
    "        \n",
    "        for k in tqdm(range(self.lenT-2), total = self.lenT-2):\n",
    "            \n",
    "            for i in range(self.len_Y):\n",
    "            \n",
    "                for j in range(self.len_X):\n",
    "                    \n",
    "                    velx0 = self.velocity_grid[i, j, 0, k]\n",
    "                    vely0 = self.velocity_grid[i, j, 1, k]\n",
    "                    \n",
    "                    vel0 = np.sqrt(velx0**2+vely0**2)\n",
    "                    \n",
    "                    velx1 = self.velocity_grid[i, j, 0, k + 1]\n",
    "                    vely1 = self.velocity_grid[i, j, 1, k + 1]\n",
    "                \n",
    "                    vel1 = np.sqrt(velx1**2+vely1**2)\n",
    "                \n",
    "                    self.TSE_bar[i, j, k] = np.abs(np.log(vel1/vel0))\n",
    "        \n",
    "        self.TSE_bar = np.nanmean(self.TSE_bar, axis = 2)/(self.tN-self.t0)\n",
    "        \n",
    "        return self.TRA_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Analytic_methods'></a>\n",
    "# Analytic methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Hyperbolic_LCS'></a>\n",
    "## Hyperbolic LCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='local_variational_theory_hyperbolic'></a>\n",
    "###  Hyperbolic LCS from local variational theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T08:50:34.593835Z",
     "start_time": "2021-10-12T08:50:34.549532Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _hyperbolic_LCS_local_variational_theory(self, s_array = np.linspace(0, 20, 100), lamda_threshold = 1, max_distance = 1, tensorline = \"shrinklines\", max_line_length = 5):\n",
    "        \n",
    "        bool_forward = True\n",
    "        bool_backward = True\n",
    "        \n",
    "        # Define step-size to be used for integration\n",
    "        step_size = s_array[1]-s_array[0]\n",
    "        \n",
    "        # Create gridded array which store the eigenvalue and eigenvectors of the cauchy-green strain tensor\n",
    "        eigenvalue_max = np.zeros((self.len_Y, self.len_X))\n",
    "        eigenvector_max = np.zeros((self.len_Y, self.len_X, self.dim))\n",
    "        eigenvalue_min = np.zeros((self.len_Y, self.len_X))\n",
    "        eigenvector_min = np.zeros((self.len_Y, self.len_X, self.dim))\n",
    "        \n",
    "        for i in range(self.len_Y):\n",
    "        \n",
    "            for j in range(self.len_X):\n",
    "        \n",
    "                lambda_min, lambda_max, v_min, v_max = self._eigenvalues_and_eigenvectors(self.C[i, j, :, :])\n",
    "        \n",
    "                # Make sure that lambda_max and lambda_min are finite and not nan.\n",
    "                # Otherwise the gridded interpolation would not work.\n",
    "                if np.isfinite(lambda_max) and np.isfinite(lambda_min):\n",
    "                \n",
    "                    eigenvalue_max[i, j] = lambda_max\n",
    "                    eigenvalue_min[i, j] = lambda_min\n",
    "                    eigenvector_max[i, j, :] = v_max\n",
    "                    eigenvector_min[i, j, :] = v_min\n",
    "\n",
    "        # Repelling LCS (=forward shrinklines)\n",
    "        if tensorline == \"shrinklines\":\n",
    "    \n",
    "            lamda = eigenvalue_max\n",
    "            vector_field = eigenvector_min\n",
    "            \n",
    "        # Attracting LCS (=forward stretchlines)\n",
    "        elif tensorline == \"stretchlines\":\n",
    "    \n",
    "            lamda = eigenvalue_min\n",
    "            lamda_threshold = -lamda_threshold\n",
    "            vector_field = eigenvector_max\n",
    "        \n",
    "        else:    \n",
    "            print(\"Variable type should either be shrinklines or stretchlines\")\n",
    "        \n",
    "        # Find local extrema of eigenvalue field\n",
    "        peak_x, peak_y, peak_field = self._find_2D_peaks(max_distance, self.X_domain, self.Y_domain, lamda)\n",
    "        \n",
    "        self.Interp_lambda = self._gridded_Interpolation(self.Y_domain, self.X_domain, lamda, \"linear\")\n",
    "        self.Interp_lambda_max = self._gridded_Interpolation(self.Y_domain, self.X_domain, eigenvalue_max, \"linear\")\n",
    "        self.Interp_lambda_min = self._gridded_Interpolation(self.Y_domain, self.X_domain, eigenvalue_min, \"linear\")\n",
    "    \n",
    "        x_tensorlines, y_tensorlines = [], []\n",
    "        lambda_tensorlines = []\n",
    "        \n",
    "        for i in tqdm(range(len(peak_x))):\n",
    "            \n",
    "            x_tensorline_forw, y_tensorline_forw = [], []\n",
    "            x_tensorline_back, y_tensorline_back = [], []\n",
    "            lambda_tensorline_forw, lambda_tensorline_back = [], []\n",
    "            \n",
    "            x = np.array([peak_x[i], peak_y[i]])\n",
    "            bool_forward, bool_backward = True, True\n",
    "            \n",
    "            for j in range(len(x_tensorlines)):\n",
    "                \n",
    "                for k in range(len(x_tensorlines[j])):\n",
    "                    \n",
    "                    if np.sqrt((x[0]-x_tensorlines[j][k])**2+(x[1]-y_tensorlines[j][k])**2) < max_distance:\n",
    "                        bool_forward = False\n",
    "                        bool_backward = False\n",
    "                        break\n",
    "            \n",
    "            if bool_forward and bool_backward:\n",
    "                \n",
    "                x_forward = x\n",
    "                x_backward = x\n",
    "                \n",
    "                vx, vy = self._orientational_discontinuity(x, vector_field)\n",
    "                \n",
    "                x_tensorline_forw.append(x[0])\n",
    "                y_tensorline_forw.append(x[1])\n",
    "                    \n",
    "                x_prime_forward = np.array([vx, vy])\n",
    "                x_prime_backward = -np.array([vx, vy])\n",
    "                \n",
    "                dist = 0\n",
    "            \n",
    "                for s in range(len(s_array)):\n",
    "                    \n",
    "                    if bool_forward and x_prime_forward is not None:\n",
    "                        x_old_forw = x_forward\n",
    "                        x_forward, x_prime_forward = self._RK4_tensorlines_orientational_discontinuity(x_forward, x_prime_forward, step_size, vector_field) \n",
    "                        if x_forward is not None:\n",
    "                        \n",
    "                            dist += np.sqrt((x_forward[0]-x_old_forw[0])**2+(x_forward[1]-x_old_forw[1])**2)\n",
    "                            lamda_dummy = self.Interp_lambda(x_forward[1], x_forward[0])\n",
    "                        \n",
    "                            if dist < max_line_length and lamda_dummy > lamda_threshold and (np.min(self.X_domain) < x_forward[0] < np.max(self.X_domain)) and (np.min(self.Y_domain) < x_forward[1] < np.max(self.Y_domain)):\n",
    "                                x_tensorline_forw.append(x_forward[0])\n",
    "                                y_tensorline_forw.append(x_forward[1])\n",
    "                                lambda_tensorline_forw.append(lamda_dummy)\n",
    "                    \n",
    "                        else:\n",
    "                        \n",
    "                            bool_forward = False\n",
    "                            \n",
    "                    if bool_backward and (x_prime_forward is not None):\n",
    "                        x_old_back = x_backward\n",
    "                        x_backward, x_prime_backward = self._RK4_tensorlines_orientational_discontinuity(x_backward, x_prime_backward, step_size, vector_field) \n",
    "                        if x_backward is not None:\n",
    "                        \n",
    "                            dist += np.sqrt((x_backward[0]-x_old_back[0])**2+(x_backward[1]-x_old_back[1])**2)\n",
    "                            lamda_dummy = self.Interp_lambda(x_backward[1], x_backward[0])\n",
    "                            \n",
    "                            if dist < max_line_length and lamda_dummy > lamda_threshold and (np.min(self.X_domain) < x_backward[0] < np.max(self.X_domain)) and (np.min(self.Y_domain) < x_backward[1] < np.max(self.Y_domain)):\n",
    "                                x_tensorline_back.append(x_backward[0])\n",
    "                                y_tensorline_back.append(x_backward[1])\n",
    "                                lambda_tensorline_back.append(lamda_dummy)\n",
    "                    \n",
    "                        else:\n",
    "                        \n",
    "                            bool_backward = False\n",
    "                        \n",
    "                x_tensorline = np.append(np.flip(x_tensorline_back), x_tensorline_forw)\n",
    "                y_tensorline = np.append(np.flip(y_tensorline_back), y_tensorline_forw)\n",
    "            \n",
    "                x_tensorlines.append(x_tensorline)\n",
    "                y_tensorlines.append(y_tensorline)\n",
    "                lambda_tensorlines.append(np.mean(np.append(np.flip(lambda_tensorline_back), lambda_tensorline_forw)))\n",
    "            \n",
    "        return x_tensorlines, y_tensorlines, lambda_tensorlines, peak_x, peak_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorlines - autonomous differential equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T08:50:34.609792Z",
     "start_time": "2021-10-12T08:50:34.594832Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _differential_system_tensorlines_orientational_discontinuity(self, x, x_prime, vector_field):\n",
    "        \n",
    "        vx, vy = self._orientational_discontinuity(x, vector_field)\n",
    "        \n",
    "        if vx is not None:\n",
    "        \n",
    "            lambda_max = self.Interp_lambda_max(x[1], x[0])[0][0]\n",
    "            lambda_min = self.Interp_lambda_min(x[1], x[0])[0][0]\n",
    "        \n",
    "            alpha = ((lambda_max-lambda_min)/(lambda_max+lambda_min))**2\n",
    "            \n",
    "            scaling = np.sign(vx*x_prime[0]+vy*x_prime[1])*alpha\n",
    "            \n",
    "            return scaling*np.array([vx, vy])\n",
    "        \n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Orientational discontinuity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T08:50:34.625749Z",
     "start_time": "2021-10-12T08:50:34.610789Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _orientational_discontinuity(self, x, vector_field):\n",
    "        \n",
    "        # Check for orientational discontinuity by introducing appropriate scaling\n",
    "        idx_x = np.searchsorted(self.X_domain[0,:], x[0])\n",
    "        idx_y = np.searchsorted(self.Y_domain[:,0], x[1])\n",
    "        \n",
    "        if 0 < idx_x < self.X_domain.shape[1] and 0 < idx_y < self.X_domain.shape[0]:\n",
    "    \n",
    "            X, Y = self.X_domain[idx_y-1:idx_y+1, idx_x-1:idx_x+1], self.Y_domain[idx_y-1:idx_y+1, idx_x-1:idx_x+1]\n",
    "    \n",
    "            vx_grid = np.array([[vector_field[idx_y-1,idx_x-1, 0], vector_field[idx_y, idx_x-1, 0]],\n",
    "                      [vector_field[idx_y-1,idx_x, 0], vector_field[idx_y, idx_x, 0]]])\n",
    "            vy_grid = np.array([[vector_field[idx_y-1,idx_x-1, 1], vector_field[idx_y, idx_x-1, 1]],\n",
    "                      [vector_field[idx_y-1,idx_x, 1], vector_field[idx_y, idx_x, 1]]])\n",
    "        \n",
    "            for i in range(self.dim):\n",
    "                for j in range(self.dim):\n",
    "                    if vx_grid[0, 0]*vx_grid[i, j]+vy_grid[0, 0]*vy_grid[i, j] < 0:\n",
    "                        vx_grid[i, j] = -vx_grid[i, j]\n",
    "                        vy_grid[i, j] = -vy_grid[i, j]\n",
    "    \n",
    "            vx_Interp = self._gridded_Interpolation(Y, X, vx_grid, \"linear\")\n",
    "            vy_Interp = self._gridded_Interpolation(Y, X, vy_grid, \"linear\")\n",
    "        \n",
    "            return vx_Interp(x[1], x[0])[0][0], vy_Interp(x[1], x[0])[0][0]\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steady $ 4^{th} $-order Runge - Kutta Integration handling orientational discontinuities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T08:50:34.641706Z",
     "start_time": "2021-10-12T08:50:34.626746Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _RK4_tensorlines_orientational_discontinuity(self, x, x_prime, ds, vector_field):\n",
    "        \n",
    "        # Define starting point.\n",
    "        x1 = x\n",
    "        \n",
    "        # If x is outside defined domain --> vel is None --> _RK4 returns \"None\" and integration will stop.\n",
    "        \n",
    "        loc = self._check_location(x1)[0]\n",
    "        \n",
    "        if loc != \"IN\" or self.Interp_lambda_max(x1[1], x1[0])[0][0] < 1:\n",
    "            return None, None\n",
    "        \n",
    "        # Compute x_prime at the beginning of the time-step\n",
    "        x_prime = self._differential_system_tensorlines_orientational_discontinuity(x1, x_prime, vector_field)\n",
    "        if x_prime is None:\n",
    "            return None, None\n",
    "        k1 = ds * x_prime\n",
    "\n",
    "        #  position and time at the first midpoint.\n",
    "        x2 = x1 + .5 * k1\n",
    "        loc = self._check_location(x2)[0]\n",
    "        \n",
    "        if loc != \"IN\" or self.Interp_lambda_max(x2[1], x2[0])[0][0] < 1:\n",
    "            return None, None\n",
    "        \n",
    "        # Compute x_prime at the first midpoint.\n",
    "        x_prime = self._differential_system_tensorlines_orientational_discontinuity(x2, x_prime, vector_field)\n",
    "        if x_prime is None:\n",
    "            return None, None\n",
    "        k2 = ds * x_prime\n",
    "\n",
    "        # Update position at the second midpoint.\n",
    "        x3 = x1 + .5 * k2\n",
    "    \n",
    "        loc = self._check_location(x3)[0]\n",
    "        if loc != \"IN\" or self.Interp_lambda_max(x3[1], x3[0])[0][0] < 1: \n",
    "            return None, None\n",
    "    \n",
    "        # Compute velocity at the second midpoint.\n",
    "        x_prime = self._differential_system_tensorlines_orientational_discontinuity(x3, x_prime, vector_field)\n",
    "        if x_prime is None:\n",
    "            return None, None\n",
    "        k3 = ds * x_prime\n",
    "    \n",
    "        # Update position at the endpoint.\n",
    "        x4 = x1 + k3\n",
    "    \n",
    "        loc = self._check_location(x4)[0]\n",
    "        if loc != \"IN\" or self.Interp_lambda_max(x4[1], x4[0])[0][0] < 1:\n",
    "            return None, None\n",
    "    \n",
    "        # Compute velocity at the end of the time-step.\n",
    "        x_prime = self._differential_system_tensorlines_orientational_discontinuity(x4, x_prime, vector_field) \n",
    "        if x_prime is None:\n",
    "            return None, None\n",
    "        k4 = ds * x_prime\n",
    "    \n",
    "        # define list for velocity and positions of particle\n",
    "        x_prime_update = []\n",
    "        x_update = []\n",
    "        \n",
    "        # Compute velocity\n",
    "        for j in range(self.dim):\n",
    "            # Update velocity of particles\n",
    "            x_prime_update.append(1.0 / 6.0*(k1[j] + 2 * k2[j] + 2 * k3[j] + k4[j])/ds)\n",
    "    \n",
    "        # Integration x <-- x + x_prime*ds\n",
    "        for j in range(self.dim):\n",
    "            # Update position of particles\n",
    "            x_update.append(x[j] + x_prime_update[j]*ds)\n",
    "\n",
    "        x_update = np.array(x_update)\n",
    "        x_prime_update = np.array(x_prime_update)\n",
    "        \n",
    "        if self._check_location(x_update)[0] != \"IN\" or self.Interp_lambda_max(x_update[1], x_update[0])[0][0] < 1: \n",
    "            return None, None\n",
    "    \n",
    "        return x_update, x_prime_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='elliptic_LCS'></a>\n",
    "## Elliptic LCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='local_variational_theory_elliptic'></a>\n",
    "### Elliptic LCS from local variational theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T08:50:34.656666Z",
     "start_time": "2021-10-12T08:50:34.642703Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _elliptic_LCS_local_variational_theory(self, s_array = np.linspace(0, 20, 100), len_poincare = 3):\n",
    "        \n",
    "        bool_elliptic = True\n",
    "        \n",
    "        # Shearlines\n",
    "        self.shear_vector = np.zeros((self.len_Y, self.len_X))\n",
    "        \n",
    "        # Step-size to be used for integration\n",
    "        step_size = s_array[1]-s_array[0]\n",
    "        \n",
    "        for i in range(self.len_Y):\n",
    "        \n",
    "            for j in range(self.len_X):\n",
    "        \n",
    "                lambda_min, lambda_max, v_min, v_max = self._eigenvalues_and_eigenvectors(self.C[i, j, :, :])\n",
    "        \n",
    "                # Make sure that lambda_max and lambda_min are finite and not nan.\n",
    "                # Otherwise the gridded interpolation would not work.\n",
    "                if np.isfinite(lambda_max) and np.isfinite(lambda_min):\n",
    "                    \n",
    "                    denom = np.sqrt(lambda_min)+np.sqrt(lambda_max)\n",
    "                \n",
    "                    self.shear_vector[i, j, :] = np.sqrt(np.sqrt(lambda_max)/denom)*v_min+np.sqrt(np.sqrt(lambda_min)/denom)*v_max\n",
    "        \n",
    "        self._singularity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical detection of singularities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T08:50:34.671626Z",
     "start_time": "2021-10-12T08:50:34.657663Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _singularity(self):\n",
    "        \n",
    "        f = self.C[:, :, 0, 0]-self.C[:, :, 1, 1]\n",
    "        g = self.C[:, :, 0, 1]\n",
    "    \n",
    "        x_singularity, y_singularity = [], []\n",
    "        \n",
    "        for i in range(self.len_Y-1):\n",
    "            \n",
    "            for j in range(self.len_X-1):\n",
    "                \n",
    "                f_0 = np.max(f[i:i+2, j:j+2].ravel()) >= 0 and np.min(f[i:i+2, j:j+2].ravel()) <= 0\n",
    "                g_0 = np.max(g[i:i+2, j:j+2].ravel()) >= 0 and np.min(g[i:i+2, j:j+2].ravel()) <= 0\n",
    "                \n",
    "                lamda_min, lamda_max, _, _ = self._eigenvalues_and_eigenvectors(self.C[i, j, :, :])\n",
    "                \n",
    "                # 0.9 < det(C) < 1.1  \n",
    "                det_C = self.C[i, j, 0, 0]*self.C[i, j, 1, 1]-self.C[i, j, 1, 0]*self.C[i, j, 0, 1]\n",
    "                filter_singularity = .8 < det_C < 1.2\n",
    "                \n",
    "                if f_0 and g_0 and filter_singularity:\n",
    "                    \n",
    "                    x, y = self.X_domain[i, j], self.Y_domain[i, j]\n",
    "                    \n",
    "                    x_singularity.append(self.X_domain[i, j]+self.dx/2)\n",
    "                    y_singularity.append(self.Y_domain[i, j]+self.dy/2)\n",
    "        \n",
    "        return x_singularity, y_singularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T08:50:34.686586Z",
     "start_time": "2021-10-12T08:50:34.672625Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _singularity_type(self, x, y, poincare_length, n_points):\n",
    "        \n",
    "        for i in range(0, poincare_length, n_points):\n",
    "            \n",
    "            f_theta = []\n",
    "\n",
    "            for theta in range(0, 2*np.pi):\n",
    "                \n",
    "                x_circle = x+i*np.cos(theta)\n",
    "                y_circle = y+i*np.sin(theta)\n",
    "                \n",
    "                xi_1 = self._orientational_discontinuity(x)\n",
    "                \n",
    "                if xi_1 is None:\n",
    "                    \n",
    "                    break\n",
    "                \n",
    "                else:\n",
    "                \n",
    "                    xi_1_abs = np.sqrt(xi_1[0]**2+xi_1[1]**2)\n",
    "                \n",
    "                    f_theta.append(abs(xi_1[0]*i*np.cos(theta)+xi_1[1]*i*np.sin(theta))/(xi_1_abs*i))\n",
    "        \n",
    "            import matplotlib.pyplot as plt\n",
    "        \n",
    "            plt.plot(f_theta)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poincare section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T08:50:34.701546Z",
     "start_time": "2021-10-12T08:50:34.687584Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _poincare_section(self, x_singularity, y_singularity):\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T08:50:34.717503Z",
     "start_time": "2021-10-12T08:50:34.702544Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _hyperbolic_LCS_global_variational_theory(self):\n",
    "        \n",
    "        print(\"=================Hyperbolic LCS from global variational theory=================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T08:50:34.733461Z",
     "start_time": "2021-10-12T08:50:34.718501Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _elliptic_LCS_global_variational_theory(self):\n",
    "        \n",
    "        print(\"=================Elliptic LCS from global variational theory=================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T08:50:34.748421Z",
     "start_time": "2021-10-12T08:50:34.734458Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _vorticity(self, t):\n",
    "        \n",
    "        self.omega = np.zeros((self.len_Y, self.len_X))\n",
    "        \n",
    "        for i in range(self.len_Y):\n",
    "            \n",
    "            for j in range(self.len_X):\n",
    "                \n",
    "                x = np.array([self.X_domain[i, j], self.Y_domain[i, j]])\n",
    "    \n",
    "                W = self._vorticity_tensor(x, t)\n",
    "                \n",
    "                self.omega[i, j] = W[0, 1]-W[1, 0]\n",
    "                \n",
    "        return self.omega              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T08:50:34.763381Z",
     "start_time": "2021-10-12T08:50:34.749419Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _find_ridges(self, Field, threshold = None, method = \"threshold\", resolution = 1, ds = 1, n_iterations = 100):\n",
    "        \n",
    "        sign = 1\n",
    "            \n",
    "        if threshold is None:\n",
    "            \n",
    "            print(\"Threshold value is None --> Specify threshold.\")\n",
    "            print(\"If not specified, threshold is set to \", 0.1, \" of the maximum value of the given scalar field\")\n",
    "            \n",
    "            threshold = .5*np.nanmax(Field)\n",
    "            \n",
    "        if method == \"threshold\":\n",
    "            \n",
    "            mask = (Field >= threshold)\n",
    "            \n",
    "            extrema_x = self.X_domain[mask].ravel()\n",
    "            extrema_y = self.Y_domain[mask].ravel()\n",
    "            \n",
    "            return extrema_x, extrema_y\n",
    "            \n",
    "        elif method == \"gradient\":\n",
    "            \n",
    "            Field_nan = Field.copy()\n",
    "            \n",
    "            Field[np.isnan(Field)] = 0\n",
    "            \n",
    "            Interpolant_Field = self._gridded_Interpolation(self.Y_domain, self.X_domain, Field, method = \"cubic\")\n",
    "            \n",
    "            grad_Field = np.zeros((Field.shape[0], Field.shape[1], 2))\n",
    "            \n",
    "            for i in range(1, Field.shape[0]-1):\n",
    "                \n",
    "                for j in range(1, Field.shape[1]-1):\n",
    "                    \n",
    "                    dy = (self.Y_domain[i+1,0] - self.Y_domain[i-1, 0])/2\n",
    "                    dx = (self.X_domain[0, j+1] - self.X_domain[0, j-1])/2\n",
    "\n",
    "                    grad_Field[i, j, 0] = (Interpolant_Field(self.Y_domain[i, j], self.X_domain[i, j]+.1*dx)[0][0]-Interpolant_Field(self.Y_domain[i, j], self.X_domain[i, j]-.1*dx)[0][0])/(2*.1*dx)\n",
    "                    grad_Field[i, j, 1] = (Interpolant_Field(self.Y_domain[i, j]+.1*dy, self.X_domain[i, j])[0][0]-Interpolant_Field(self.Y_domain[i, j]-.1*dy, self.X_domain[i, j])[0][0])/(2*.1*dy)\n",
    "        \n",
    "            grad_Fieldx = grad_Field[:, :, 0]\n",
    "            grad_Fieldy = grad_Field[:, :, 1]\n",
    "            grad_Fieldx[np.isnan(grad_Fieldx)] = 0\n",
    "            grad_Fieldy[np.isnan(grad_Fieldy)] = 0\n",
    "            \n",
    "            Interpolant_gradx_Field = self._gridded_Interpolation(self.Y_domain, self.X_domain, grad_Fieldx)\n",
    "            Interpolant_grady_Field = self._gridded_Interpolation(self.Y_domain, self.X_domain, grad_Fieldy)\n",
    "            \n",
    "            x_grid = np.linspace(np.min(self.X_domain), np.max(self.X_domain), self.Y_domain.shape[0]*resolution)\n",
    "            y_grid = np.linspace(np.min(self.Y_domain), np.max(self.Y_domain), self.Y_domain.shape[1]*resolution)\n",
    "            \n",
    "            extrema_x = []\n",
    "            extrema_y = []\n",
    "            \n",
    "            for x in tqdm(x_grid, total = len(x_grid)):\n",
    "                    \n",
    "                for y in y_grid:\n",
    "                    \n",
    "                    x_eval = x\n",
    "                    y_eval = y\n",
    "    \n",
    "                    loc = self._check_location(np.array([x_eval, y_eval]))[0]\n",
    "                \n",
    "                    gradient = 10\n",
    "                    \n",
    "                    iter = 0\n",
    "                        \n",
    "                    while iter < n_iterations and loc == \"IN\" and Interpolant_Field(y_eval, x_eval)[0][0] > threshold:\n",
    "                        \n",
    "                        gradx = Interpolant_gradx_Field(y_eval, x_eval)[0][0]\n",
    "                        grady = Interpolant_grady_Field(y_eval, x_eval)[0][0]\n",
    "                        \n",
    "                        gradient = np.sqrt(gradx**2+grady**2)\n",
    "                        \n",
    "                        x_eval = x_eval + sign * ds * gradx/gradient*dx\n",
    "                        y_eval = y_eval + sign * ds * grady/gradient*dy\n",
    "                        \n",
    "                        iter += 1\n",
    "                        \n",
    "                        if np.min(self.X_domain) < x_eval < np.max(self.X_domain) and np.min(self.Y_domain) < y_eval < np.max(self.Y_domain):\n",
    "                        \n",
    "                            loc = self._check_location(np.array([x_eval, y_eval]))[0]\n",
    "                            \n",
    "                        else:\n",
    "                            \n",
    "                            loc = \"OUT\"\n",
    "                        \n",
    "                        idx_x = np.searchsorted(self.X_domain[0,:], x_eval)\n",
    "                        idx_y = np.searchsorted(self.Y_domain[:,0], y_eval)\n",
    "                        \n",
    "                        if 0 < idx_x < self.len_X-1 and 0 < idx_y < self.len_Y-1:\n",
    "                        \n",
    "                            if iter == n_iterations and loc == \"IN\" and np.isfinite(np.sum(Field_nan[idx_y-1:idx_y+1,idx_x-1:idx_x+1])):\n",
    "                    \n",
    "                                extrema_x.append(x_eval)\n",
    "                                extrema_y.append(y_eval)\n",
    "            \n",
    "            return extrema_x, extrema_y\n",
    "\n",
    "        else:\n",
    "            \n",
    "            print(\"The method argument is not valid. Use either threshold or gradient\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local extrema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T08:50:34.779338Z",
     "start_time": "2021-10-12T08:50:34.764379Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _find_2D_peaks(self, max_distance, X, Y, Field):\n",
    "        \n",
    "        def _find_all_local_maxima(X, Y, Field):\n",
    "            \n",
    "            loc_max_x, loc_max_y, loc_max_field = [], [], []\n",
    "            \n",
    "            for i in tqdm(range(2, X.shape[0]-2)):\n",
    "                \n",
    "                for j in range(2, Y.shape[1]-2):\n",
    "                    \n",
    "                    if np.isfinite(Field[i, j]) and Field[i, j] > Field[i+1, j] and Field[i, j] > Field[i-1, j] and Field[i, j] > Field[i, j+1] and Field[i, j] > Field[i, j-1]:\n",
    "                        \n",
    "                        loc_max_x.append(X[i, j])\n",
    "                        loc_max_y.append(Y[i, j])\n",
    "                        loc_max_field.append(Field[i, j])\n",
    "            \n",
    "            return loc_max_x, loc_max_y, loc_max_field\n",
    "        \n",
    "        loc_max_x, loc_max_y, loc_max_field = _find_all_local_maxima(X, Y, Field)\n",
    "        \n",
    "        n_loc_max = len(loc_max_x)\n",
    "        \n",
    "        peak_x, peak_y, peak_field = [], [], []\n",
    "        \n",
    "        for i in range(n_loc_max):\n",
    "            \n",
    "            bool_loc_max = True\n",
    "    \n",
    "            for j in range(n_loc_max):\n",
    "            \n",
    "                if i != j and loc_max_field[i] < loc_max_field[j] and np.sqrt((loc_max_x[i]-loc_max_x[j])**2+(loc_max_y[i]-loc_max_y[j])**2) <= max_distance:\n",
    "                    \n",
    "                    bool_loc_max = False\n",
    "                \n",
    "            if bool_loc_max:\n",
    "                \n",
    "                peak_x.append(loc_max_x[i])\n",
    "                peak_y.append(loc_max_y[i])\n",
    "                peak_field.append(loc_max_field[i])\n",
    "          \n",
    "        arg_index = np.argsort(peak_field)\n",
    "        peak_x = np.flip([peak_x[i] for i in arg_index])\n",
    "        peak_y = np.flip([peak_y[i] for i in arg_index])\n",
    "        peak_field = np.flip([peak_field[i] for i in arg_index])\n",
    "    \n",
    "        return peak_x, peak_y, peak_field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contourlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T08:50:34.794302Z",
     "start_time": "2021-10-12T08:50:34.780336Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _contourlines(self, X, Y, Field, n_contours):\n",
    "        \n",
    "        from skimage import measure\n",
    "        from shapely.geometry import Polygon, Point\n",
    "        \n",
    "        Field_min = np.nanmin(Field) + (np.nanmax(Field)-np.nanmin(Field))/n_contours\n",
    "        Field_max = np.nanmax(Field) - (np.nanmax(Field)-np.nanmin(Field))/n_contours\n",
    "        \n",
    "        closed_contours = []\n",
    "        \n",
    "        for i in np.linspace(Field_min, Field_max, n_contours):\n",
    "            \n",
    "            contour = measure.find_contours(Field, i)\n",
    "            \n",
    "            for c in contour:\n",
    "                \n",
    "                if c[-1, 0] == c[0, 0] and c[-1, 1] == c[0, 1]:\n",
    "\n",
    "                    x_contour = np.min(X)+(np.max(X)-np.min(X))/(X.shape[1])*c[:, 1]\n",
    "                    y_contour = np.min(Y)+(np.max(Y)-np.min(Y))/(Y.shape[0])*c[:, 0]\n",
    "            \n",
    "                    closed_contours.append(np.array([x_contour, y_contour]).T)\n",
    "    \n",
    "        return closed_contours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Area of polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T08:50:34.809574Z",
     "start_time": "2021-10-12T08:50:34.795298Z"
    }
   },
   "outputs": [],
   "source": [
    "    def polygonArea(self, X, Y):\n",
    "\n",
    "        # Initialize area\n",
    "        area = 0.0\n",
    " \n",
    "        # Calculate value of shoelace formula\n",
    "        j = len(X) - 1\n",
    "        for i in range(0,len(X)):\n",
    "            area += (X[j] + X[i]) * (Y[j] - Y[i])\n",
    "            j = i # j is previous vertex to i\n",
    "        \n",
    "        return abs(area / 2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convexity deficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T08:50:34.824882Z",
     "start_time": "2021-10-12T08:50:34.810571Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _convexity_deficiency(self, contours):\n",
    "\n",
    "        from scipy.spatial import ConvexHull, convex_hull_plot_2d\n",
    "        from shapely.geometry import Polygon, Point\n",
    "            \n",
    "        X = contours[:, 0]\n",
    "        Y = contours[:, 1]\n",
    "            \n",
    "        points = np.array([X, Y]).T\n",
    "            \n",
    "        Polygon_area = self.polygonArea(X, Y)\n",
    "            \n",
    "        if Polygon_area > 0:\n",
    "                \n",
    "            hull = ConvexHull(points)\n",
    "            \n",
    "            Convex_area = hull.volume\n",
    "            \n",
    "            return (Convex_area-Polygon_area)/Polygon_area\n",
    "                \n",
    "        else:\n",
    "                \n",
    "            return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-07T14:56:53.432657Z",
     "start_time": "2021-10-07T14:56:53.418677Z"
    }
   },
   "source": [
    "## Point inside polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T08:50:34.839844Z",
     "start_time": "2021-10-12T08:50:34.825880Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _point_inside_polygon(self, x, y, contour):\n",
    "        \n",
    "        from shapely.geometry import Point\n",
    "        from shapely.geometry.polygon import Polygon\n",
    "        \n",
    "        point = Point(x, y)\n",
    "        polygon = Polygon(contour)\n",
    "        \n",
    "        return polygon.contains(point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length closed material line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T08:50:34.854830Z",
     "start_time": "2021-10-12T08:50:34.840840Z"
    }
   },
   "outputs": [],
   "source": [
    "    def _length_closed_material_line(self, contour):\n",
    "        \n",
    "        from shapely.geometry.polygon import Polygon\n",
    "        \n",
    "        length = 0\n",
    "        \n",
    "        for i in range(contour.shape[0]-1):\n",
    "            \n",
    "            length += np.sqrt((contour[i+1,0]-contour[i,0])**2+(contour[i+1,1]-contour[i,1])**2)\n",
    "        \n",
    "        return length"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "411.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
